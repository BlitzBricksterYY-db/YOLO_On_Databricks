{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5da57367-ba6b-4f58-9304-ecf5ba3ec2bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "%markdown\n",
    "# Ultralytics YOLO Training on Databricks Serverless GPU Compute (SGC)\n",
    "\n",
    "This notebook demonstrates how to set up and run distributed YOLO model training using Databricks Serverless GPU Compute with proper resource management and MLflow integration.\n",
    "\n",
    "## ğŸš€ Overview\n",
    "\n",
    "This implementation leverages:\n",
    "- **Databricks Serverless GPU Compute (SGC)** for scalable, on-demand GPU resources\n",
    "- **Ultralytics YOLO v11** for state-of-the-art object detection\n",
    "- **Distributed Training** with PyTorch DDP and NCCL backend\n",
    "- **MLflow** for experiment tracking and model management\n",
    "- **Unity Catalog Volumes** for persistent data storage\n",
    "\n",
    "## ğŸ“‹ Prerequisites\n",
    "\n",
    "### Environment Requirements\n",
    "- Databricks Runtime with GPU support\n",
    "- Access to Serverless GPU Compute\n",
    "- Unity Catalog enabled workspace\n",
    "- MLflow experiment tracking permissions\n",
    "\n",
    "### Required Packages\n",
    "```python\n",
    "ultralytics==8.3.204\n",
    "mlflow>=3.0\n",
    "nvidia-ml-py==13.580.82  # GPU monitoring\n",
    "pyrsmi==0.2.0           # AMD GPU support (optional)\n",
    "threadpoolctl==3.1.0\n",
    "```\n",
    "\n",
    "## ğŸ—ï¸ Architecture\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    Databricks SGC Cluster                  â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚  GPU 0    â”‚  GPU 1    â”‚  GPU 2    â”‚  ...    â”‚  GPU N-1    â”‚\n",
    "â”‚  Rank 0   â”‚  Rank 1   â”‚  Rank 2   â”‚  ...    â”‚  Rank N-1   â”‚\n",
    "â”‚  (Master) â”‚           â”‚           â”‚         â”‚             â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "           â”‚\n",
    "           â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    Unity Catalog Volume                     â”‚\n",
    "â”‚  /Volumes/catalog/schema/volume/                           â”‚\n",
    "â”‚  â”œâ”€â”€ data/           # Training datasets                   â”‚\n",
    "â”‚  â”œâ”€â”€ raw_model/      # Pre-trained models                 â”‚\n",
    "â”‚  â””â”€â”€ training_runs/  # Output artifacts                   â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "           â”‚\n",
    "           â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                      MLflow Tracking                       â”‚\n",
    "â”‚  â€¢ Experiment logging                                      â”‚\n",
    "â”‚  â€¢ Model versioning                                        â”‚\n",
    "â”‚  â€¢ Metrics & artifacts                                     â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "## ğŸ”§ Setup Instructions\n",
    "\n",
    "### 1. Environment Setup\n",
    "\n",
    "First, use A10 SGC with Env version 4, then install required packages and restart Python runtime:\n",
    "\n",
    "```python\n",
    "%pip install -U mlflow>=3.0\n",
    "%pip install ultralytics==8.3.204\n",
    "%pip install nvidia-ml-py==13.580.82\n",
    "dbutils.library.restartPython()\n",
    "```\n",
    "\n",
    "### 2. Unity Catalog Configuration\n",
    "\n",
    "Create necessary catalog structure:\n",
    "\n",
    "```sql\n",
    "CREATE CATALOG IF NOT EXISTS your_catalog;\n",
    "CREATE SCHEMA IF NOT EXISTS your_catalog.computer_vision;\n",
    "CREATE VOLUME IF NOT EXISTS your_catalog.computer_vision.yolo;\n",
    "```\n",
    "\n",
    "### 3. Data Preparation\n",
    "\n",
    "**Supported Dataset Formats:**\n",
    "- COCO format (recommended)\n",
    "- YOLO format\n",
    "- Custom annotations\n",
    "\n",
    "**Directory Structure:**\n",
    "```\n",
    "/Volumes/catalog/schema/volume/\n",
    "â”œâ”€â”€ data/\n",
    "â”‚   â””â”€â”€ dataset_name/\n",
    "â”‚       â”œâ”€â”€ images/\n",
    "â”‚       â”‚   â”œâ”€â”€ train/\n",
    "â”‚       â”‚   â””â”€â”€ val/\n",
    "â”‚       â”œâ”€â”€ labels/\n",
    "â”‚       â”‚   â”œâ”€â”€ train/\n",
    "â”‚       â”‚   â””â”€â”€ val/\n",
    "â”‚       â””â”€â”€ data.yaml\n",
    "â”œâ”€â”€ raw_model/\n",
    "â”‚   â””â”€â”€ yolo11n.pt\n",
    "â””â”€â”€ training_runs/\n",
    "```\n",
    "\n",
    "### 4. MLflow Configuration\n",
    "\n",
    "Set up experiment tracking:\n",
    "\n",
    "```python\n",
    "experiment_name = \"/Users/your.email@company.com/YOLO_Experiments\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "os.environ['MLFLOW_ENABLE_SYSTEM_METRICS_LOGGING'] = \"true\"\n",
    "```\n",
    "\n",
    "## ğŸš€ Distributed Training\n",
    "\n",
    "### Key Features\n",
    "\n",
    "1. **Automatic GPU Detection**: Dynamically scales across available GPUs\n",
    "2. **Fault Tolerance**: Proper cleanup with try/finally blocks\n",
    "3. **Resource Management**: Prevents NCCL process group leaks\n",
    "4. **MLflow Integration**: Automatic logging of metrics, models, and artifacts\n",
    "\n",
    "### Training Configuration\n",
    "\n",
    "```python\n",
    "@distributed(gpus=8, gpu_type='A10', remote=True)\n",
    "def train_fn(world_size=None, parent_run_id=None):\n",
    "    try:\n",
    "        # Setup distributed environment\n",
    "        rank, world_size, device = setup()\n",
    "        \n",
    "        # Initialize YOLO model\n",
    "        model = YOLO(\"yolo11n.pt\")\n",
    "        \n",
    "        # Start training with optimized parameters\n",
    "        model.train(\n",
    "            task=\"detect\",\n",
    "            batch=16,                    # Adjust based on GPU memory\n",
    "            device=[LOCAL_RANK],\n",
    "            data=data_yaml_path,\n",
    "            epochs=100,\n",
    "            project=training_output_path,\n",
    "            exist_ok=True,\n",
    "            # Data augmentation\n",
    "            fliplr=1,                   # Horizontal flip probability\n",
    "            flipud=1,                   # Vertical flip probability  \n",
    "            perspective=0.001,          # Perspective transformation\n",
    "            degrees=0.45                # Rotation degrees\n",
    "        )\n",
    "        \n",
    "        # Validation and export (rank 0 only)\n",
    "        if RANK in (0, -1):\n",
    "            model.val()\n",
    "            model.export()\n",
    "            \n",
    "    finally:\n",
    "        # Critical: Always cleanup to prevent resource leaks\n",
    "        cleanup()\n",
    "```\n",
    "\n",
    "## ğŸ“Š Monitoring & Debugging\n",
    "\n",
    "### Environment Variables\n",
    "\n",
    "```python\n",
    "# Debugging options\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"0\"  # Set to \"1\" for debugging\n",
    "os.environ[\"NCCL_DEBUG\"] = \"INFO\"         # NCCL communication logs\n",
    "os.environ[\"NCCL_DEBUG_SUBSYS\"] = \"ALL\"   # Detailed NCCL debugging\n",
    "```\n",
    "\n",
    "### MLflow System Metrics\n",
    "\n",
    "Enable comprehensive system monitoring:\n",
    "\n",
    "```python\n",
    "os.environ['MLFLOW_ENABLE_SYSTEM_METRICS_LOGGING'] = \"true\"\n",
    "```\n",
    "\n",
    "This captures:\n",
    "- GPU utilization and memory\n",
    "- CPU usage and memory\n",
    "- Network I/O\n",
    "- Disk I/O\n",
    "\n",
    "## ğŸ” Troubleshooting\n",
    "\n",
    "### Common Issues\n",
    "\n",
    "1. **NCCL Process Group Warning**\n",
    "   ```\n",
    "   ProcessGroupNCCL.cpp:1479] Warning: destroy_process_group() was not called\n",
    "   ```\n",
    "   **Solution**: Ensure `cleanup()` is called in finally block\n",
    "\n",
    "2. **CUDA Out of Memory**\n",
    "   ```\n",
    "   RuntimeError: CUDA out of memory\n",
    "   ```\n",
    "   **Solution**: Reduce batch size or use gradient accumulation\n",
    "\n",
    "3. **Distributed Training Hangs**\n",
    "   **Solution**: Check NCCL environment variables and network connectivity\n",
    "\n",
    "### Debug Commands\n",
    "\n",
    "```python\n",
    "# Check GPU availability\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"GPU count: {torch.cuda.device_count()}\")\n",
    "\n",
    "# Verify distributed setup\n",
    "print(f\"Rank: {RANK}, Local Rank: {LOCAL_RANK}\")\n",
    "print(f\"World Size: {dist.get_world_size() if dist.is_initialized() else 'Not initialized'}\")\n",
    "```\n",
    "\n",
    "## ğŸ“š References\n",
    "\n",
    "- [Ultralytics YOLO Documentation](https://docs.ultralytics.com/)\n",
    "- [Databricks Serverless GPU Compute](https://docs.databricks.com/en/compute/serverless-gpu.html)\n",
    "- [PyTorch Distributed Training](https://pytorch.org/docs/stable/distributed.html)\n",
    "- [MLflow Model Registry](https://mlflow.org/docs/latest/model-registry.html)\n",
    "- [Unity Catalog Volumes](https://docs.databricks.com/en/catalog/volumes.html)\n",
    "\n",
    "## ğŸ·ï¸ Model Versioning\n",
    "\n",
    "This setup automatically:\n",
    "- Logs training metrics to MLflow\n",
    "- Saves model artifacts to Unity Catalog\n",
    "- Creates model signatures for deployment\n",
    "- Tracks hyperparameters and dataset versions\n",
    "\n",
    "## ğŸš¦ Best Practices\n",
    "\n",
    "1. **Resource Management**: Always use try/finally for cleanup\n",
    "2. **Data Location**: Use Unity Catalog Volumes for overall governance\n",
    "3. **Batch Size**: Start with smaller batches and scale up\n",
    "4. **Monitoring**: Enable MLflow system metrics\n",
    "5. **Checkpointing**: Save intermediate results for long training runs (under /tmp/)\n",
    "6. **Validation**: Run validation on rank 0 only to avoid conflicts\n",
    "\n",
    "---\n",
    "\n",
    "**Next Steps**: Run the cells below to start your YOLO training pipeline! ğŸ¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd8b9120-1b2e-4f47-85b8-26f4ee90bda4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.12/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n  import pynvml  # type: ignore[import]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: serverless_gpu is in Beta. The API is subject to change.\nLooking in indexes: [REDACTED], [REDACTED]\nCollecting mlflow>=3.0\n  Downloading mlflow-3.4.0-py3-none-any.whl.metadata (30 kB)\nCollecting mlflow-skinny==3.4.0 (from mlflow>=3.0)\n  Downloading mlflow_skinny-3.4.0-py3-none-any.whl.metadata (31 kB)\nCollecting mlflow-tracing==3.4.0 (from mlflow>=3.0)\n  Downloading mlflow_tracing-3.4.0-py3-none-any.whl.metadata (19 kB)\nCollecting Flask<4 (from mlflow>=3.0)\n  Downloading flask-3.1.2-py3-none-any.whl.metadata (3.2 kB)\nCollecting alembic!=1.10.0,<2 (from mlflow>=3.0)\n  Downloading alembic-1.17.0-py3-none-any.whl.metadata (7.2 kB)\nRequirement already satisfied: cryptography<46,>=43.0.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow>=3.0) (43.0.3)\nCollecting docker<8,>=4.0.0 (from mlflow>=3.0)\n  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\nCollecting fastmcp<3,>=2.0.0 (from mlflow>=3.0)\n  Downloading fastmcp-2.12.4-py3-none-any.whl.metadata (19 kB)\nCollecting graphene<4 (from mlflow>=3.0)\n  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\nCollecting gunicorn<24 (from mlflow>=3.0)\n  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\nRequirement already satisfied: matplotlib<4 in /databricks/python3/lib/python3.12/site-packages (from mlflow>=3.0) (3.10.0)\nRequirement already satisfied: numpy<3 in /databricks/python3/lib/python3.12/site-packages (from mlflow>=3.0) (2.1.3)\nRequirement already satisfied: pandas<3 in /databricks/python3/lib/python3.12/site-packages (from mlflow>=3.0) (2.2.3)\nRequirement already satisfied: pyarrow<22,>=4.0.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow>=3.0) (19.0.1)\nRequirement already satisfied: scikit-learn<2 in /databricks/python3/lib/python3.12/site-packages (from mlflow>=3.0) (1.6.1)\nRequirement already satisfied: scipy<2 in /databricks/python3/lib/python3.12/site-packages (from mlflow>=3.0) (1.15.1)\nCollecting sqlalchemy<3,>=1.4.0 (from mlflow>=3.0)\n  Downloading sqlalchemy-2.0.44-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.5 kB)\nRequirement already satisfied: cachetools<7,>=5.0.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.4.0->mlflow>=3.0) (5.5.1)\nRequirement already satisfied: click<9,>=7.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.4.0->mlflow>=3.0) (8.1.7)\nRequirement already satisfied: cloudpickle<4 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.4.0->mlflow>=3.0) (3.0.0)\nRequirement already satisfied: databricks-sdk<1,>=0.20.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.4.0->mlflow>=3.0) (0.49.0)\nRequirement already satisfied: fastapi<1 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.4.0->mlflow>=3.0) (0.115.12)\nRequirement already satisfied: gitpython<4,>=3.1.9 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.4.0->mlflow>=3.0) (3.1.43)\nRequirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.4.0->mlflow>=3.0) (6.6.0)\nRequirement already satisfied: opentelemetry-api<3,>=1.9.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.4.0->mlflow>=3.0) (1.32.1)\nCollecting opentelemetry-proto<3,>=1.9.0 (from mlflow-skinny==3.4.0->mlflow>=3.0)\n  Downloading opentelemetry_proto-1.37.0-py3-none-any.whl.metadata (2.3 kB)\nRequirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.4.0->mlflow>=3.0) (1.32.1)\nRequirement already satisfied: packaging<26 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.4.0->mlflow>=3.0) (24.1)\nRequirement already satisfied: protobuf<7,>=3.12.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.4.0->mlflow>=3.0) (5.29.4)\nRequirement already satisfied: pydantic<3,>=1.10.8 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.4.0->mlflow>=3.0) (2.10.6)\nCollecting python-dotenv<2,>=0.19.0 (from mlflow-skinny==3.4.0->mlflow>=3.0)\n  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\nRequirement already satisfied: pyyaml<7,>=5.1 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.4.0->mlflow>=3.0) (6.0.2)\nRequirement already satisfied: requests<3,>=2.17.3 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.4.0->mlflow>=3.0) (2.32.3)\nRequirement already satisfied: sqlparse<1,>=0.4.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.4.0->mlflow>=3.0) (0.5.3)\nRequirement already satisfied: typing-extensions<5,>=4.0.0 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.4.0->mlflow>=3.0) (4.12.2)\nRequirement already satisfied: uvicorn<1 in /databricks/python3/lib/python3.12/site-packages (from mlflow-skinny==3.4.0->mlflow>=3.0) (0.34.2)\nCollecting Mako (from alembic!=1.10.0,<2->mlflow>=3.0)\n  Downloading mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)\nRequirement already satisfied: cffi>=1.12 in /databricks/python3/lib/python3.12/site-packages (from cryptography<46,>=43.0.0->mlflow>=3.0) (1.17.1)\nRequirement already satisfied: urllib3>=1.26.0 in /databricks/python3/lib/python3.12/site-packages (from docker<8,>=4.0.0->mlflow>=3.0) (2.3.0)\nCollecting authlib>=1.5.2 (from fastmcp<3,>=2.0.0->mlflow>=3.0)\n  Downloading authlib-1.6.5-py2.py3-none-any.whl.metadata (9.8 kB)\nCollecting cyclopts>=3.0.0 (from fastmcp<3,>=2.0.0->mlflow>=3.0)\n  Downloading cyclopts-3.24.0-py3-none-any.whl.metadata (11 kB)\nCollecting exceptiongroup>=1.2.2 (from fastmcp<3,>=2.0.0->mlflow>=3.0)\n  Downloading exceptiongroup-1.3.0-py3-none-any.whl.metadata (6.7 kB)\nCollecting httpx>=0.28.1 (from fastmcp<3,>=2.0.0->mlflow>=3.0)\n  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\nCollecting mcp<2.0.0,>=1.12.4 (from fastmcp<3,>=2.0.0->mlflow>=3.0)\n  Downloading mcp-1.17.0-py3-none-any.whl.metadata (80 kB)\nCollecting openapi-core>=0.19.5 (from fastmcp<3,>=2.0.0->mlflow>=3.0)\n  Downloading openapi_core-0.19.5-py3-none-any.whl.metadata (6.6 kB)\nCollecting openapi-pydantic>=0.5.1 (from fastmcp<3,>=2.0.0->mlflow>=3.0)\n  Downloading openapi_pydantic-0.5.1-py3-none-any.whl.metadata (10 kB)\nCollecting pydantic<3,>=1.10.8 (from mlflow-skinny==3.4.0->mlflow>=3.0)\n  Downloading pydantic-2.12.0-py3-none-any.whl.metadata (83 kB)\nCollecting pyperclip>=1.9.0 (from fastmcp<3,>=2.0.0->mlflow>=3.0)\n  Downloading pyperclip-1.11.0-py3-none-any.whl.metadata (2.4 kB)\nRequirement already satisfied: rich>=13.9.4 in /databricks/python3/lib/python3.12/site-packages (from fastmcp<3,>=2.0.0->mlflow>=3.0) (13.9.4)\nCollecting blinker>=1.9.0 (from Flask<4->mlflow>=3.0)\n  Downloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\nCollecting itsdangerous>=2.2.0 (from Flask<4->mlflow>=3.0)\n  Downloading itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\nRequirement already satisfied: jinja2>=3.1.2 in /databricks/python3/lib/python3.12/site-packages (from Flask<4->mlflow>=3.0) (3.1.5)\nRequirement already satisfied: markupsafe>=2.1.1 in /databricks/python3/lib/python3.12/site-packages (from Flask<4->mlflow>=3.0) (3.0.2)\nCollecting werkzeug>=3.1.0 (from Flask<4->mlflow>=3.0)\n  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\nCollecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow>=3.0)\n  Downloading graphql_core-3.2.6-py3-none-any.whl.metadata (11 kB)\nCollecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow>=3.0)\n  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: python-dateutil<3,>=2.7.0 in /databricks/python3/lib/python3.12/site-packages (from graphene<4->mlflow>=3.0) (2.9.0.post0)\nRequirement already satisfied: contourpy>=1.0.1 in /databricks/python3/lib/python3.12/site-packages (from matplotlib<4->mlflow>=3.0) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /databricks/python3/lib/python3.12/site-packages (from matplotlib<4->mlflow>=3.0) (0.11.0)\nRequirement already satisfied: fonttools>=4.22.0 in /databricks/python3/lib/python3.12/site-packages (from matplotlib<4->mlflow>=3.0) (4.55.3)\nRequirement already satisfied: kiwisolver>=1.3.1 in /databricks/python3/lib/python3.12/site-packages (from matplotlib<4->mlflow>=3.0) (1.4.8)\nRequirement already satisfied: pillow>=8 in /databricks/python3/lib/python3.12/site-packages (from matplotlib<4->mlflow>=3.0) (11.1.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /databricks/python3/lib/python3.12/site-packages (from matplotlib<4->mlflow>=3.0) (3.2.0)\nRequirement already satisfied: pytz>=2020.1 in /databricks/python3/lib/python3.12/site-packages (from pandas<3->mlflow>=3.0) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /databricks/python3/lib/python3.12/site-packages (from pandas<3->mlflow>=3.0) (2024.1)\nRequirement already satisfied: joblib>=1.2.0 in /databricks/python3/lib/python3.12/site-packages (from scikit-learn<2->mlflow>=3.0) (1.4.2)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /databricks/python3/lib/python3.12/site-packages (from scikit-learn<2->mlflow>=3.0) (3.5.0)\nCollecting greenlet>=1 (from sqlalchemy<3,>=1.4.0->mlflow>=3.0)\n  Downloading greenlet-3.2.4-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.1 kB)\nRequirement already satisfied: pycparser in /databricks/python3/lib/python3.12/site-packages (from cffi>=1.12->cryptography<46,>=43.0.0->mlflow>=3.0) (2.21)\nRequirement already satisfied: attrs>=23.1.0 in /databricks/python3/lib/python3.12/site-packages (from cyclopts>=3.0.0->fastmcp<3,>=2.0.0->mlflow>=3.0) (24.3.0)\nCollecting docstring-parser>=0.15 (from cyclopts>=3.0.0->fastmcp<3,>=2.0.0->mlflow>=3.0)\n  Downloading docstring_parser-0.17.0-py3-none-any.whl.metadata (3.5 kB)\nCollecting rich-rst<2.0.0,>=1.3.1 (from cyclopts>=3.0.0->fastmcp<3,>=2.0.0->mlflow>=3.0)\n  Downloading rich_rst-1.3.1-py3-none-any.whl.metadata (6.0 kB)\nRequirement already satisfied: google-auth~=2.0 in /databricks/python3/lib/python3.12/site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.4.0->mlflow>=3.0) (2.40.0)\nRequirement already satisfied: starlette<0.47.0,>=0.40.0 in /databricks/python3/lib/python3.12/site-packages (from fastapi<1->mlflow-skinny==3.4.0->mlflow>=3.0) (0.46.2)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /databricks/python3/lib/python3.12/site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==3.4.0->mlflow>=3.0) (4.0.11)\nRequirement already satisfied: anyio in /databricks/python3/lib/python3.12/site-packages (from httpx>=0.28.1->fastmcp<3,>=2.0.0->mlflow>=3.0) (4.6.2)\nRequirement already satisfied: certifi in /databricks/python3/lib/python3.12/site-packages (from httpx>=0.28.1->fastmcp<3,>=2.0.0->mlflow>=3.0) (2025.1.31)\nRequirement already satisfied: httpcore==1.* in /databricks/python3/lib/python3.12/site-packages (from httpx>=0.28.1->fastmcp<3,>=2.0.0->mlflow>=3.0) (1.0.2)\nRequirement already satisfied: idna in /databricks/python3/lib/python3.12/site-packages (from httpx>=0.28.1->fastmcp<3,>=2.0.0->mlflow>=3.0) (3.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /databricks/python3/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.28.1->fastmcp<3,>=2.0.0->mlflow>=3.0) (0.14.0)\nRequirement already satisfied: zipp>=0.5 in /databricks/python3/lib/python3.12/site-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.4.0->mlflow>=3.0) (3.21.0)\nCollecting httpx-sse>=0.4 (from mcp<2.0.0,>=1.12.4->fastmcp<3,>=2.0.0->mlflow>=3.0)\n  Downloading httpx_sse-0.4.3-py3-none-any.whl.metadata (9.7 kB)\nRequirement already satisfied: jsonschema>=4.20.0 in /databricks/python3/lib/python3.12/site-packages (from mcp<2.0.0,>=1.12.4->fastmcp<3,>=2.0.0->mlflow>=3.0) (4.23.0)\nCollecting pydantic-settings>=2.5.2 (from mcp<2.0.0,>=1.12.4->fastmcp<3,>=2.0.0->mlflow>=3.0)\n  Downloading pydantic_settings-2.11.0-py3-none-any.whl.metadata (3.4 kB)\nCollecting python-multipart>=0.0.9 (from mcp<2.0.0,>=1.12.4->fastmcp<3,>=2.0.0->mlflow>=3.0)\n  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\nCollecting sse-starlette>=1.6.1 (from mcp<2.0.0,>=1.12.4->fastmcp<3,>=2.0.0->mlflow>=3.0)\n  Downloading sse_starlette-3.0.2-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: isodate in /databricks/python3/lib/python3.12/site-packages (from openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow>=3.0) (0.6.1)\nCollecting jsonschema-path<0.4.0,>=0.3.1 (from openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow>=3.0)\n  Downloading jsonschema_path-0.3.4-py3-none-any.whl.metadata (4.3 kB)\nCollecting more-itertools (from openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow>=3.0)\n  Downloading more_itertools-10.8.0-py3-none-any.whl.metadata (39 kB)\nCollecting openapi-schema-validator<0.7.0,>=0.6.0 (from openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow>=3.0)\n  Downloading openapi_schema_validator-0.6.3-py3-none-any.whl.metadata (5.4 kB)\nCollecting openapi-spec-validator<0.8.0,>=0.7.1 (from openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow>=3.0)\n  Downloading openapi_spec_validator-0.7.2-py3-none-any.whl.metadata (5.7 kB)\nCollecting parse (from openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow>=3.0)\n  Downloading parse-1.20.2-py2.py3-none-any.whl.metadata (22 kB)\nCollecting werkzeug>=3.1.0 (from Flask<4->mlflow>=3.0)\n  Downloading werkzeug-3.1.1-py3-none-any.whl.metadata (3.7 kB)\nRequirement already satisfied: deprecated>=1.2.6 in /databricks/python3/lib/python3.12/site-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==3.4.0->mlflow>=3.0) (1.2.13)\nRequirement already satisfied: opentelemetry-semantic-conventions==0.53b1 in /databricks/python3/lib/python3.12/site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.4.0->mlflow>=3.0) (0.53b1)\nRequirement already satisfied: annotated-types>=0.6.0 in /databricks/python3/lib/python3.12/site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.4.0->mlflow>=3.0) (0.7.0)\nCollecting pydantic-core==2.41.1 (from pydantic<3,>=1.10.8->mlflow-skinny==3.4.0->mlflow>=3.0)\n  Downloading pydantic_core-2.41.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\nCollecting typing-extensions<5,>=4.0.0 (from mlflow-skinny==3.4.0->mlflow>=3.0)\n  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\nCollecting typing-inspection>=0.4.2 (from pydantic<3,>=1.10.8->mlflow-skinny==3.4.0->mlflow>=3.0)\n  Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\nCollecting email-validator>=2.0.0 (from pydantic[email]>=2.11.7->fastmcp<3,>=2.0.0->mlflow>=3.0)\n  Downloading email_validator-2.3.0-py3-none-any.whl.metadata (26 kB)\nRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow>=3.0) (1.16.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /databricks/python3/lib/python3.12/site-packages (from requests<3,>=2.17.3->mlflow-skinny==3.4.0->mlflow>=3.0) (3.3.2)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /databricks/python3/lib/python3.12/site-packages (from rich>=13.9.4->fastmcp<3,>=2.0.0->mlflow>=3.0) (2.2.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /databricks/python3/lib/python3.12/site-packages (from rich>=13.9.4->fastmcp<3,>=2.0.0->mlflow>=3.0) (2.15.1)\nRequirement already satisfied: sniffio>=1.1 in /databricks/python3/lib/python3.12/site-packages (from anyio->httpx>=0.28.1->fastmcp<3,>=2.0.0->mlflow>=3.0) (1.3.0)\nRequirement already satisfied: wrapt<2,>=1.10 in /databricks/python3/lib/python3.12/site-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==3.4.0->mlflow>=3.0) (1.17.0)\nCollecting dnspython>=2.0.0 (from email-validator>=2.0.0->pydantic[email]>=2.11.7->fastmcp<3,>=2.0.0->mlflow>=3.0)\n  Downloading dnspython-2.8.0-py3-none-any.whl.metadata (5.7 kB)\nRequirement already satisfied: smmap<6,>=3.0.1 in /databricks/python3/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.4.0->mlflow>=3.0) (5.0.0)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /databricks/python3/lib/python3.12/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.4.0->mlflow>=3.0) (0.2.8)\nRequirement already satisfied: rsa<5,>=3.1.4 in /databricks/python3/lib/python3.12/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.4.0->mlflow>=3.0) (4.9.1)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /databricks/python3/lib/python3.12/site-packages (from jsonschema>=4.20.0->mcp<2.0.0,>=1.12.4->fastmcp<3,>=2.0.0->mlflow>=3.0) (2023.7.1)\nRequirement already satisfied: referencing>=0.28.4 in /databricks/python3/lib/python3.12/site-packages (from jsonschema>=4.20.0->mcp<2.0.0,>=1.12.4->fastmcp<3,>=2.0.0->mlflow>=3.0) (0.30.2)\nRequirement already satisfied: rpds-py>=0.7.1 in /databricks/python3/lib/python3.12/site-packages (from jsonschema>=4.20.0->mcp<2.0.0,>=1.12.4->fastmcp<3,>=2.0.0->mlflow>=3.0) (0.22.3)\nCollecting pathable<0.5.0,>=0.4.1 (from jsonschema-path<0.4.0,>=0.3.1->openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow>=3.0)\n  Downloading pathable-0.4.4-py3-none-any.whl.metadata (1.8 kB)\nRequirement already satisfied: mdurl~=0.1 in /databricks/python3/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=13.9.4->fastmcp<3,>=2.0.0->mlflow>=3.0) (0.1.0)\nRequirement already satisfied: rfc3339-validator in /databricks/python3/lib/python3.12/site-packages (from openapi-schema-validator<0.7.0,>=0.6.0->openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow>=3.0) (0.1.4)\nCollecting lazy-object-proxy<2.0.0,>=1.7.1 (from openapi-spec-validator<0.8.0,>=0.7.1->openapi-core>=0.19.5->fastmcp<3,>=2.0.0->mlflow>=3.0)\n  Downloading lazy_object_proxy-1.12.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (5.1 kB)\nCollecting docutils (from rich-rst<2.0.0,>=1.3.1->cyclopts>=3.0.0->fastmcp<3,>=2.0.0->mlflow>=3.0)\n  Downloading docutils-0.22.2-py3-none-any.whl.metadata (15 kB)\nCollecting anyio (from httpx>=0.28.1->fastmcp<3,>=2.0.0->mlflow>=3.0)\n  Downloading anyio-4.11.0-py3-none-any.whl.metadata (4.1 kB)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /databricks/python3/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.4.0->mlflow>=3.0) (0.4.8)\nDownloading mlflow-3.4.0-py3-none-any.whl (26.7 MB)\n\u001B[?25l   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m0.0/26.7 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[91mâ•¸\u001B[0m \u001B[32m26.5/26.7 MB\u001B[0m \u001B[31m165.6 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\u001B[2K   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m26.7/26.7 MB\u001B[0m \u001B[31m116.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading mlflow_skinny-3.4.0-py3-none-any.whl (2.2 MB)\n\u001B[?25l   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m0.0/2.2 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m2.2/2.2 MB\u001B[0m \u001B[31m101.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading mlflow_tracing-3.4.0-py3-none-any.whl (1.2 MB)\n\u001B[?25l   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m0.0/1.2 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m1.2/1.2 MB\u001B[0m \u001B[31m108.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading alembic-1.17.0-py3-none-any.whl (247 kB)\nDownloading docker-7.1.0-py3-none-any.whl (147 kB)\nDownloading fastmcp-2.12.4-py3-none-any.whl (329 kB)\nDownloading flask-3.1.2-py3-none-any.whl (103 kB)\nDownloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\nDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\nDownloading sqlalchemy-2.0.44-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n\u001B[?25l   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m0.0/3.3 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m3.3/3.3 MB\u001B[0m \u001B[31m145.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading authlib-1.6.5-py2.py3-none-any.whl (243 kB)\nDownloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\nDownloading cyclopts-3.24.0-py3-none-any.whl (86 kB)\nDownloading exceptiongroup-1.3.0-py3-none-any.whl (16 kB)\nDownloading graphql_core-3.2.6-py3-none-any.whl (203 kB)\nDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\nDownloading greenlet-3.2.4-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (607 kB)\n\u001B[?25l   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m0.0/607.6 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m607.6/607.6 kB\u001B[0m \u001B[31m66.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading httpx-0.28.1-py3-none-any.whl (73 kB)\nDownloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)\nDownloading mcp-1.17.0-py3-none-any.whl (167 kB)\nDownloading openapi_core-0.19.5-py3-none-any.whl (106 kB)\nDownloading openapi_pydantic-0.5.1-py3-none-any.whl (96 kB)\nDownloading opentelemetry_proto-1.37.0-py3-none-any.whl (72 kB)\nDownloading pydantic-2.12.0-py3-none-any.whl (459 kB)\nDownloading pydantic_core-2.41.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n\u001B[?25l   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m0.0/2.1 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m2.1/2.1 MB\u001B[0m \u001B[31m122.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading pyperclip-1.11.0-py3-none-any.whl (11 kB)\nDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\nDownloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\nDownloading werkzeug-3.1.1-py3-none-any.whl (224 kB)\nDownloading mako-1.3.10-py3-none-any.whl (78 kB)\nDownloading docstring_parser-0.17.0-py3-none-any.whl (36 kB)\nDownloading email_validator-2.3.0-py3-none-any.whl (35 kB)\nDownloading httpx_sse-0.4.3-py3-none-any.whl (9.0 kB)\nDownloading jsonschema_path-0.3.4-py3-none-any.whl (14 kB)\nDownloading openapi_schema_validator-0.6.3-py3-none-any.whl (8.8 kB)\nDownloading openapi_spec_validator-0.7.2-py3-none-any.whl (39 kB)\nDownloading pydantic_settings-2.11.0-py3-none-any.whl (48 kB)\nDownloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\nDownloading rich_rst-1.3.1-py3-none-any.whl (11 kB)\nDownloading sse_starlette-3.0.2-py3-none-any.whl (11 kB)\nDownloading anyio-4.11.0-py3-none-any.whl (109 kB)\nDownloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\nDownloading more_itertools-10.8.0-py3-none-any.whl (69 kB)\nDownloading parse-1.20.2-py2.py3-none-any.whl (20 kB)\nDownloading dnspython-2.8.0-py3-none-any.whl (331 kB)\nDownloading lazy_object_proxy-1.12.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (71 kB)\nDownloading pathable-0.4.4-py3-none-any.whl (9.6 kB)\nDownloading docutils-0.22.2-py3-none-any.whl (632 kB)\n\u001B[?25l   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m0.0/632.7 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m632.7/632.7 kB\u001B[0m \u001B[31m70.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hInstalling collected packages: pyperclip, parse, werkzeug, typing-extensions, python-multipart, python-dotenv, pathable, opentelemetry-proto, more-itertools, Mako, lazy-object-proxy, itsdangerous, httpx-sse, gunicorn, greenlet, graphql-core, docutils, docstring-parser, dnspython, blinker, typing-inspection, sqlalchemy, pydantic-core, jsonschema-path, graphql-relay, Flask, exceptiongroup, email-validator, docker, anyio, sse-starlette, rich-rst, pydantic, httpx, graphene, authlib, alembic, pydantic-settings, openapi-schema-validator, openapi-pydantic, cyclopts, openapi-spec-validator, mlflow-tracing, mlflow-skinny, mcp, openapi-core, fastmcp, mlflow\n  Attempting uninstall: typing-extensions\n    Found existing installation: typing_extensions 4.12.2\n    Not uninstalling typing-extensions at /databricks/python3/lib/python3.12/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-cea1accf-8a62-4d8e-b722-9efae50781ae\n    Can't uninstall 'typing_extensions'. No files were found to uninstall.\n  Attempting uninstall: blinker\n    Found existing installation: blinker 1.7.0\n    Not uninstalling blinker at /usr/lib/python3/dist-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-cea1accf-8a62-4d8e-b722-9efae50781ae\n    Can't uninstall 'blinker'. No files were found to uninstall.\n  Attempting uninstall: pydantic-core\n    Found existing installation: pydantic_core 2.27.2\n    Not uninstalling pydantic-core at /databricks/python3/lib/python3.12/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-cea1accf-8a62-4d8e-b722-9efae50781ae\n    Can't uninstall 'pydantic_core'. No files were found to uninstall.\n  Attempting uninstall: anyio\n    Found existing installation: anyio 4.6.2\n    Not uninstalling anyio at /databricks/python3/lib/python3.12/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-cea1accf-8a62-4d8e-b722-9efae50781ae\n    Can't uninstall 'anyio'. No files were found to uninstall.\n  Attempting uninstall: pydantic\n    Found existing installation: pydantic 2.10.6\n    Not uninstalling pydantic at /databricks/python3/lib/python3.12/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-cea1accf-8a62-4d8e-b722-9efae50781ae\n    Can't uninstall 'pydantic'. No files were found to uninstall.\n  Attempting uninstall: httpx\n    Found existing installation: httpx 0.27.0\n    Not uninstalling httpx at /databricks/python3/lib/python3.12/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-cea1accf-8a62-4d8e-b722-9efae50781ae\n    Can't uninstall 'httpx'. No files were found to uninstall.\n  Attempting uninstall: mlflow-skinny\n    Found existing installation: mlflow-skinny 2.22.0\n    Not uninstalling mlflow-skinny at /databricks/python3/lib/python3.12/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-cea1accf-8a62-4d8e-b722-9efae50781ae\n    Can't uninstall 'mlflow-skinny'. No files were found to uninstall.\n\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndatabricks-serverless-gpu 0.5.6 requires databricks-connect<16,>=15.4.2, but you have databricks-connect 17.2.2 which is incompatible.\ndatabricks-serverless-gpu 0.5.6 requires mlflow<3.0,>=2.17, but you have mlflow 3.4.0 which is incompatible.\u001B[0m\u001B[31m\n\u001B[0mSuccessfully installed Flask-3.1.2 Mako-1.3.10 alembic-1.17.0 anyio-4.11.0 authlib-1.6.5 blinker-1.9.0 cyclopts-3.24.0 dnspython-2.8.0 docker-7.1.0 docstring-parser-0.17.0 docutils-0.22.2 email-validator-2.3.0 exceptiongroup-1.3.0 fastmcp-2.12.4 graphene-3.4.3 graphql-core-3.2.6 graphql-relay-3.2.0 greenlet-3.2.4 gunicorn-23.0.0 httpx-0.28.1 httpx-sse-0.4.3 itsdangerous-2.2.0 jsonschema-path-0.3.4 lazy-object-proxy-1.12.0 mcp-1.17.0 mlflow-3.4.0 mlflow-skinny-3.4.0 mlflow-tracing-3.4.0 more-itertools-10.8.0 openapi-core-0.19.5 openapi-pydantic-0.5.1 openapi-schema-validator-0.6.3 openapi-spec-validator-0.7.2 opentelemetry-proto-1.37.0 parse-1.20.2 pathable-0.4.4 pydantic-2.12.0 pydantic-core-2.41.1 pydantic-settings-2.11.0 pyperclip-1.11.0 python-dotenv-1.1.1 python-multipart-0.0.20 rich-rst-1.3.1 sqlalchemy-2.0.44 sse-starlette-3.0.2 typing-extensions-4.15.0 typing-inspection-0.4.2 werkzeug-3.1.1\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"ts\": \"2025-10-13 04:56:27.298\", \"level\": \"WARNING\", \"logger\": \"pyspark.sql.connect.logging\", \"msg\": \"Effective usage policy for this session is 7da2ca5b-25b8-3e87-9a2c-f86eb19d101c.\", \"context\": {}}\n{\"ts\": \"2025-10-13 04:56:27.298\", \"level\": \"WARNING\", \"logger\": \"pyspark.sql.connect.logging\", \"msg\": \"Effective usage policy for this session is 7da2ca5b-25b8-3e87-9a2c-f86eb19d101c.\", \"context\": {}}\n{\"ts\": \"2025-10-13 04:56:27.298\", \"level\": \"WARNING\", \"logger\": \"pyspark.sql.connect.logging\", \"msg\": \"Effective usage policy for this session is 7da2ca5b-25b8-3e87-9a2c-f86eb19d101c.\", \"context\": {}}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: [REDACTED], [REDACTED]\nCollecting threadpoolctl==3.1.0\n  Downloading threadpoolctl-3.1.0-py3-none-any.whl.metadata (9.2 kB)\nDownloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\nInstalling collected packages: threadpoolctl\n  Attempting uninstall: threadpoolctl\n    Found existing installation: threadpoolctl 3.5.0\n    Not uninstalling threadpoolctl at /databricks/python3/lib/python3.12/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-cea1accf-8a62-4d8e-b722-9efae50781ae\n    Can't uninstall 'threadpoolctl'. No files were found to uninstall.\nSuccessfully installed threadpoolctl-3.1.0\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\nLooking in indexes: [REDACTED], [REDACTED]\nCollecting ultralytics==8.3.204\n  Downloading ultralytics-8.3.204-py3-none-any.whl.metadata (37 kB)\nRequirement already satisfied: numpy>=1.23.0 in /databricks/python3/lib/python3.12/site-packages (from ultralytics==8.3.204) (2.1.3)\nRequirement already satisfied: matplotlib>=3.3.0 in /databricks/python3/lib/python3.12/site-packages (from ultralytics==8.3.204) (3.10.0)\nCollecting opencv-python>=4.6.0 (from ultralytics==8.3.204)\n  Downloading opencv_python-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (19 kB)\nRequirement already satisfied: pillow>=7.1.2 in /databricks/python3/lib/python3.12/site-packages (from ultralytics==8.3.204) (11.1.0)\nRequirement already satisfied: pyyaml>=5.3.1 in /databricks/python3/lib/python3.12/site-packages (from ultralytics==8.3.204) (6.0.2)\nRequirement already satisfied: requests>=2.23.0 in /databricks/python3/lib/python3.12/site-packages (from ultralytics==8.3.204) (2.32.3)\nRequirement already satisfied: scipy>=1.4.1 in /databricks/python3/lib/python3.12/site-packages (from ultralytics==8.3.204) (1.15.1)\nRequirement already satisfied: torch>=1.8.0 in /databricks/python3/lib/python3.12/site-packages (from ultralytics==8.3.204) (2.7.1)\nRequirement already satisfied: torchvision>=0.9.0 in /databricks/python3/lib/python3.12/site-packages (from ultralytics==8.3.204) (0.22.1)\nRequirement already satisfied: psutil in /databricks/python3/lib/python3.12/site-packages (from ultralytics==8.3.204) (5.9.0)\nCollecting polars (from ultralytics==8.3.204)\n  Downloading polars-1.34.0-py3-none-any.whl.metadata (10 kB)\nCollecting ultralytics-thop>=2.0.0 (from ultralytics==8.3.204)\n  Downloading ultralytics_thop-2.0.17-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: contourpy>=1.0.1 in /databricks/python3/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics==8.3.204) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /databricks/python3/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics==8.3.204) (0.11.0)\nRequirement already satisfied: fonttools>=4.22.0 in /databricks/python3/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics==8.3.204) (4.55.3)\nRequirement already satisfied: kiwisolver>=1.3.1 in /databricks/python3/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics==8.3.204) (1.4.8)\nRequirement already satisfied: packaging>=20.0 in /databricks/python3/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics==8.3.204) (24.1)\nRequirement already satisfied: pyparsing>=2.3.1 in /databricks/python3/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics==8.3.204) (3.2.0)\nRequirement already satisfied: python-dateutil>=2.7 in /databricks/python3/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics==8.3.204) (2.9.0.post0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /databricks/python3/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics==8.3.204) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics==8.3.204) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /databricks/python3/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics==8.3.204) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics==8.3.204) (2025.1.31)\nRequirement already satisfied: filelock in /databricks/python3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics==8.3.204) (3.13.1)\nRequirement already satisfied: typing-extensions>=4.10.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-cea1accf-8a62-4d8e-b722-9efae50781ae/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics==8.3.204) (4.15.0)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics==8.3.204) (74.0.0)\nRequirement already satisfied: sympy>=1.13.3 in /databricks/python3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics==8.3.204) (1.13.3)\nRequirement already satisfied: networkx in /databricks/python3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics==8.3.204) (3.4.2)\nRequirement already satisfied: jinja2 in /databricks/python3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics==8.3.204) (3.1.5)\nRequirement already satisfied: fsspec in /databricks/python3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics==8.3.204) (2023.5.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /databricks/python3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics==8.3.204) (12.6.77)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /databricks/python3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics==8.3.204) (12.6.77)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /databricks/python3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics==8.3.204) (12.6.80)\nRequirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /databricks/python3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics==8.3.204) (9.5.1.17)\nRequirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /databricks/python3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics==8.3.204) (12.6.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /databricks/python3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics==8.3.204) (11.3.0.4)\nRequirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /databricks/python3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics==8.3.204) (10.3.7.77)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /databricks/python3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics==8.3.204) (11.7.1.2)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /databricks/python3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics==8.3.204) (12.5.4.2)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /databricks/python3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics==8.3.204) (0.6.3)\nRequirement already satisfied: nvidia-nccl-cu12==2.26.2 in /databricks/python3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics==8.3.204) (2.26.2)\nRequirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /databricks/python3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics==8.3.204) (12.6.77)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /databricks/python3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics==8.3.204) (12.6.85)\nRequirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /databricks/python3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics==8.3.204) (1.11.1.6)\nRequirement already satisfied: triton==3.3.1 in /databricks/python3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics==8.3.204) (3.3.1)\nCollecting polars-runtime-32==1.34.0 (from polars->ultralytics==8.3.204)\n  Downloading polars_runtime_32-1.34.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics==8.3.204) (1.16.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /databricks/python3/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics==8.3.204) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /databricks/python3/lib/python3.12/site-packages (from jinja2->torch>=1.8.0->ultralytics==8.3.204) (3.0.2)\nDownloading ultralytics-8.3.204-py3-none-any.whl (1.1 MB)\n\u001B[?25l   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m0.0/1.1 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m1.1/1.1 MB\u001B[0m \u001B[31m11.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading opencv_python-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (67.0 MB)\n\u001B[?25l   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m0.0/67.0 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[91mâ”â”â”\u001B[0m\u001B[90mâ•º\u001B[0m\u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m5.5/67.0 MB\u001B[0m \u001B[31m29.0 MB/s\u001B[0m eta \u001B[36m0:00:03\u001B[0m\r\u001B[2K   \u001B[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[91mâ•¸\u001B[0m\u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m23.1/67.0 MB\u001B[0m \u001B[31m59.4 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\u001B[2K   \u001B[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[91mâ•¸\u001B[0m\u001B[90mâ”â”â”â”â”â”\u001B[0m \u001B[32m56.9/67.0 MB\u001B[0m \u001B[31m96.7 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\u001B[2K   \u001B[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[91mâ•¸\u001B[0m \u001B[32m66.8/67.0 MB\u001B[0m \u001B[31m104.3 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\u001B[2K   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m67.0/67.0 MB\u001B[0m \u001B[31m83.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading ultralytics_thop-2.0.17-py3-none-any.whl (28 kB)\nDownloading polars-1.34.0-py3-none-any.whl (772 kB)\n\u001B[?25l   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m0.0/772.7 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m772.7/772.7 kB\u001B[0m \u001B[31m82.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading polars_runtime_32-1.34.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (40.3 MB)\n\u001B[?25l   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m0.0/40.3 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[91mâ•¸\u001B[0m\u001B[90mâ”â”\u001B[0m \u001B[32m37.7/40.3 MB\u001B[0m \u001B[31m190.6 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\u001B[2K   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m40.3/40.3 MB\u001B[0m \u001B[31m126.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hInstalling collected packages: polars-runtime-32, opencv-python, polars, ultralytics-thop, ultralytics\nSuccessfully installed opencv-python-4.12.0.88 polars-1.34.0 polars-runtime-32-1.34.0 ultralytics-8.3.204 ultralytics-thop-2.0.17\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\nLooking in indexes: [REDACTED], [REDACTED]\nRequirement already satisfied: nvidia-ml-py==13.580.82 in /databricks/python3/lib/python3.12/site-packages (13.580.82)\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\nLooking in indexes: [REDACTED], [REDACTED]\nCollecting pyrsmi==0.2.0\n  Downloading pyrsmi-0.2.0-py2.py3-none-any.whl.metadata (5.7 kB)\nDownloading pyrsmi-0.2.0-py2.py3-none-any.whl (12 kB)\nInstalling collected packages: pyrsmi\nSuccessfully installed pyrsmi-0.2.0\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "import serverless_gpu\n",
    "%pip install -U mlflow>=3.0\n",
    "%pip install threadpoolctl==3.1.0\n",
    "%pip install ultralytics==8.3.204\n",
    "%pip install nvidia-ml-py==13.580.82 # for later mlflow GPU monitoring\n",
    "%pip install pyrsmi==0.2.0 # for later mlflow AMD GPU monitoring if you have AMD\n",
    "\n",
    "\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae4f83f4-ba4c-4aac-b4f2-3444f106388d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ user config directory '/home/spark-787e12c8-81d4-49dc-a0a6-34/.config/Ultralytics' is not writeable, using '/tmp/Ultralytics'. Set YOLO_CONFIG_DIR to override.\nCreating new Ultralytics Settings v0.0.6 file âœ… \nView Ultralytics Settings with 'yolo settings' or at '/tmp/Ultralytics/settings.json'\nUpdate Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\nWarning: serverless_gpu is in Beta. The API is subject to change.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.databricks.v1+torch_distributed_hint": "",
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\n",
    "from ultralytics import YOLO\n",
    "from serverless_gpu import distributed\n",
    "import mlflow\n",
    "\n",
    "\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import mlflow\n",
    "import torch.distributed as dist\n",
    "from ultralytics import settings\n",
    "from mlflow.types.schema import Schema, ColSpec\n",
    "from mlflow.models.signature import ModelSignature\n",
    "from ultralytics.utils import RANK, LOCAL_RANK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42531dbd-3ea0-4570-ba97-35dc3c03058d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n  \"settings_version\": \"0.0.6\",\r\n  \"datasets_dir\": \"/Workspace/Users/yang.yang@databricks.com/SGC_YOLO_Test/datasets\",\r\n  \"weights_dir\": \"weights\",\r\n  \"runs_dir\": \"runs\",\r\n  \"uuid\": \"fa4e172fb516d115a0014dcd2d01d8017ac8c1517cfd0b6c4f930e9fcff83a7c\",\r\n  \"sync\": true,\r\n  \"api_key\": \"\",\r\n  \"openai_api_key\": \"\",\r\n  \"clearml\": true,\r\n  \"comet\": true,\r\n  \"dvc\": true,\r\n  \"hub\": true,\r\n  \"mlflow\": true,\r\n  \"neptune\": true,\r\n  \"raytune\": true,\r\n  \"tensorboard\": false,\r\n  \"wandb\": false,\r\n  \"vscode_msg\": true,\r\n  \"openvino_msg\": true\r\n}"
     ]
    }
   ],
   "source": [
    "%cat /tmp/Ultralytics/settings.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c531b751-2f78-4dc6-96dc-309b003cb196",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Setup I/O Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70d14e30-c744-4232-bf5f-8ad34d9f26e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "create catalog if not exists yyang;\n",
    "create schema if not exists yyang.computer_vision;\n",
    "create volume if not exists yyang.computer_vision.yolo;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c934f1e5-273f-4448-ad06-984749ce9d20",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "project_location = '/Volumes/yyang/computer_vision/yolo/'\n",
    "os.makedirs(f'{project_location}/training_runs/', exist_ok=True)\n",
    "os.makedirs(f'{project_location}/data/', exist_ok=True)\n",
    "os.makedirs(f'{project_location}/raw_model/', exist_ok=True)\n",
    "\n",
    "# volume folder in UC.\n",
    "volume_project_location = f'{project_location}/training_results/'\n",
    "os.makedirs(volume_project_location, exist_ok=True)\n",
    "\n",
    "# or alternatively, ephemeral /tmp/ project location on VM\n",
    "tmp_project_location = \"/tmp/training_results/\"\n",
    "os.makedirs(tmp_project_location, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fcb57faa-8cd4-4efe-bc23-88aebc793fd0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Image Data I/O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d365dc7c-dfda-4b2d-a892-551c92acad16",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'/Workspace/Users/yang.yang@databricks.com/SGC_YOLO_Test'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('/Workspace/' + dbutils.notebook.entry_point.getDbutils().notebook().getContext().notebookPath().get().rsplit('/', 1)[0])\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25d1e829-1767-401e-8fcb-6a405b2afb75",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n\r100  1965  100  1965    0     0   7969      0 --:--:-- --:--:-- --:--:--  7969\n"
     ]
    }
   ],
   "source": [
    "%sh\n",
    "# curl -L https://github.com/ultralytics/ultralytics/raw/main/ultralytics/cfg/datasets/coco8.yaml -o coco8.yaml\n",
    "curl -L https://github.com/ultralytics/ultralytics/raw/main/ultralytics/cfg/datasets/coco128.yaml -o coco128.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9613b8d3-aa50-4c4b-90e6-a45581976941",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Ultralytics ğŸš€ AGPL-3.0 License - https://ultralytics.com/license\n\n# COCO128 dataset https://www.kaggle.com/datasets/ultralytics/coco128 (first 128 images from COCO train2017) by Ultralytics\n# Documentation: https://docs.ultralytics.com/datasets/detect/coco/\n# Example usage: yolo train data=coco128.yaml\n# parent\n# â”œâ”€â”€ ultralytics\n# â””â”€â”€ datasets\n#     â””â”€â”€ coco128 â† downloads here (7 MB)\n\n# Train/val/test sets as 1) dir: path/to/imgs, 2) file: path/to/imgs.txt, or 3) list: [path/to/imgs1, path/to/imgs2, ..]\npath: coco128 # dataset root dir\ntrain: images/train2017 # train images (relative to 'path') 128 images\nval: images/train2017 # val images (relative to 'path') 128 images\ntest: # test images (optional)\n\n# Classes\nnames:\n  0: person\n  1: bicycle\n  2: car\n  3: motorcycle\n  4: airplane\n  5: bus\n  6: train\n  7: truck\n  8: boat\n  9: traffic light\n  10: fire hydrant\n  11: stop sign\n  12: parking meter\n  13: bench\n  14: bird\n  15: cat\n  16: dog\n  17: horse\n  18: sheep\n  19: cow\n  20: elephant\n  21: bear\n  22: zebra\n  23: giraffe\n  24: backpack\n  25: umbrella\n  26: handbag\n  27: tie\n  28: suitcase\n  29: frisbee\n  30: skis\n  31: snowboard\n  32: sports ball\n  33: kite\n  34: baseball bat\n  35: baseball glove\n  36: skateboard\n  37: surfboard\n  38: tennis racket\n  39: bottle\n  40: wine glass\n  41: cup\n  42: fork\n  43: knife\n  44: spoon\n  45: bowl\n  46: banana\n  47: apple\n  48: sandwich\n  49: orange\n  50: broccoli\n  51: carrot\n  52: hot dog\n  53: pizza\n  54: donut\n  55: cake\n  56: chair\n  57: couch\n  58: potted plant\n  59: bed\n  60: dining table\n  61: toilet\n  62: tv\n  63: laptop\n  64: mouse\n  65: remote\n  66: keyboard\n  67: cell phone\n  68: microwave\n  69: oven\n  70: toaster\n  71: sink\n  72: refrigerator\n  73: book\n  74: clock\n  75: vase\n  76: scissors\n  77: teddy bear\n  78: hair drier\n  79: toothbrush\n\n# Download script/URL (optional)\ndownload: https://github.com/ultralytics/assets/releases/download/v0.0.0/coco128.zip\n"
     ]
    }
   ],
   "source": [
    "%sh\n",
    "# cat ./coco8.yaml\n",
    "cat ./coco128.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "359206f2-de4f-4cc5-acb5-aae5bc8cfb90",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "__REMEMBER: change below cell path for your data.yaml as input to YOLO train later__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e224cdc1-1bf0-46d7-9a59-a40642bf95b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# with open('coco8.yaml', 'r') as file:\n",
    "with open('coco128.yaml', 'r') as file:\n",
    "\n",
    "    data = file.read()\n",
    "\n",
    "#: here specific for this dataset, we have to update the .yaml file with real I/O locations.\n",
    "os.makedirs(f'{project_location}/data/coco128', exist_ok=True)\n",
    "data = data.replace('path: coco128', f'path: {project_location}data/coco128')\n",
    "\n",
    "\n",
    "# with open('coco8.yaml', 'w') as file:\n",
    "with open('coco128.yaml', 'w') as file:\n",
    "\n",
    "    file.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "010c5888-7c1c-4bd2-8f2a-7ec5ed1787c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Ultralytics ğŸš€ AGPL-3.0 License - https://ultralytics.com/license\n\n# COCO128 dataset https://www.kaggle.com/datasets/ultralytics/coco128 (first 128 images from COCO train2017) by Ultralytics\n# Documentation: https://docs.ultralytics.com/datasets/detect/coco/\n# Example usage: yolo train data=coco128.yaml\n# parent\n# â”œâ”€â”€ ultralytics\n# â””â”€â”€ datasets\n#     â””â”€â”€ coco128 â† downloads here (7 MB)\n\n# Train/val/test sets as 1) dir: path/to/imgs, 2) file: path/to/imgs.txt, or 3) list: [path/to/imgs1, path/to/imgs2, ..]\npath: /Volumes/yyang/computer_vision/yolo/data/coco128 # dataset root dir\ntrain: images/train2017 # train images (relative to 'path') 128 images\nval: images/train2017 # val images (relative to 'path') 128 images\ntest: # test images (optional)\n\n# Classes\nnames:\n  0: person\n  1: bicycle\n  2: car\n  3: motorcycle\n  4: airplane\n  5: bus\n  6: train\n  7: truck\n  8: boat\n  9: traffic light\n  10: fire hydrant\n  11: stop sign\n  12: parking meter\n  13: bench\n  14: bird\n  15: cat\n  16: dog\n  17: horse\n  18: sheep\n  19: cow\n  20: elephant\n  21: bear\n  22: zebra\n  23: giraffe\n  24: backpack\n  25: umbrella\n  26: handbag\n  27: tie\n  28: suitcase\n  29: frisbee\n  30: skis\n  31: snowboard\n  32: sports ball\n  33: kite\n  34: baseball bat\n  35: baseball glove\n  36: skateboard\n  37: surfboard\n  38: tennis racket\n  39: bottle\n  40: wine glass\n  41: cup\n  42: fork\n  43: knife\n  44: spoon\n  45: bowl\n  46: banana\n  47: apple\n  48: sandwich\n  49: orange\n  50: broccoli\n  51: carrot\n  52: hot dog\n  53: pizza\n  54: donut\n  55: cake\n  56: chair\n  57: couch\n  58: potted plant\n  59: bed\n  60: dining table\n  61: toilet\n  62: tv\n  63: laptop\n  64: mouse\n  65: remote\n  66: keyboard\n  67: cell phone\n  68: microwave\n  69: oven\n  70: toaster\n  71: sink\n  72: refrigerator\n  73: book\n  74: clock\n  75: vase\n  76: scissors\n  77: teddy bear\n  78: hair drier\n  79: toothbrush\n\n# Download script/URL (optional)\ndownload: https://github.com/ultralytics/assets/releases/download/v0.0.0/coco128.zip\n"
     ]
    }
   ],
   "source": [
    "%sh\n",
    "# cat ./coco8.yaml\n",
    "cat ./coco128.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21c1c0f6-50c9-47bb-8610-89a13cda17fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'path': '/Volumes/yyang/computer_vision/yolo/data/coco128',\n",
       " 'train': 'images/train2017',\n",
       " 'val': 'images/train2017',\n",
       " 'test': None,\n",
       " 'names': {0: 'person',\n",
       "  1: 'bicycle',\n",
       "  2: 'car',\n",
       "  3: 'motorcycle',\n",
       "  4: 'airplane',\n",
       "  5: 'bus',\n",
       "  6: 'train',\n",
       "  7: 'truck',\n",
       "  8: 'boat',\n",
       "  9: 'traffic light',\n",
       "  10: 'fire hydrant',\n",
       "  11: 'stop sign',\n",
       "  12: 'parking meter',\n",
       "  13: 'bench',\n",
       "  14: 'bird',\n",
       "  15: 'cat',\n",
       "  16: 'dog',\n",
       "  17: 'horse',\n",
       "  18: 'sheep',\n",
       "  19: 'cow',\n",
       "  20: 'elephant',\n",
       "  21: 'bear',\n",
       "  22: 'zebra',\n",
       "  23: 'giraffe',\n",
       "  24: 'backpack',\n",
       "  25: 'umbrella',\n",
       "  26: 'handbag',\n",
       "  27: 'tie',\n",
       "  28: 'suitcase',\n",
       "  29: 'frisbee',\n",
       "  30: 'skis',\n",
       "  31: 'snowboard',\n",
       "  32: 'sports ball',\n",
       "  33: 'kite',\n",
       "  34: 'baseball bat',\n",
       "  35: 'baseball glove',\n",
       "  36: 'skateboard',\n",
       "  37: 'surfboard',\n",
       "  38: 'tennis racket',\n",
       "  39: 'bottle',\n",
       "  40: 'wine glass',\n",
       "  41: 'cup',\n",
       "  42: 'fork',\n",
       "  43: 'knife',\n",
       "  44: 'spoon',\n",
       "  45: 'bowl',\n",
       "  46: 'banana',\n",
       "  47: 'apple',\n",
       "  48: 'sandwich',\n",
       "  49: 'orange',\n",
       "  50: 'broccoli',\n",
       "  51: 'carrot',\n",
       "  52: 'hot dog',\n",
       "  53: 'pizza',\n",
       "  54: 'donut',\n",
       "  55: 'cake',\n",
       "  56: 'chair',\n",
       "  57: 'couch',\n",
       "  58: 'potted plant',\n",
       "  59: 'bed',\n",
       "  60: 'dining table',\n",
       "  61: 'toilet',\n",
       "  62: 'tv',\n",
       "  63: 'laptop',\n",
       "  64: 'mouse',\n",
       "  65: 'remote',\n",
       "  66: 'keyboard',\n",
       "  67: 'cell phone',\n",
       "  68: 'microwave',\n",
       "  69: 'oven',\n",
       "  70: 'toaster',\n",
       "  71: 'sink',\n",
       "  72: 'refrigerator',\n",
       "  73: 'book',\n",
       "  74: 'clock',\n",
       "  75: 'vase',\n",
       "  76: 'scissors',\n",
       "  77: 'teddy bear',\n",
       "  78: 'hair drier',\n",
       "  79: 'toothbrush'},\n",
       " 'download': 'https://github.com/ultralytics/assets/releases/download/v0.0.0/coco128.zip'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "# with open('./coco8.yaml', 'r') as file:\n",
    "with open('./coco128.yaml', 'r') as file:\n",
    "    data = yaml.safe_load(file)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6aef5597-e8f6-4bba-b01b-6b63424f114a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# import requests\n",
    "# import tarfile\n",
    "# import io\n",
    "\n",
    "# response = requests.get(data['download'])\n",
    "# tar = tarfile.open(fileobj=io.BytesIO(response.content), mode='r:gz')\n",
    "# tar.extractall(path=data['path'])\n",
    "# tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ffda763-fe59-4d0c-9422-c42f9a0ffdea",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Extract Zip File from URL and Save to Path"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/yyang/computer_vision/yolo/data\n"
     ]
    }
   ],
   "source": [
    "import requests, zipfile, io\n",
    "\n",
    "response = requests.get(data['download'])\n",
    "z = zipfile.ZipFile(io.BytesIO(response.content))\n",
    "extraction_path = '/'.join(data['path'].split('/')[:-1]) # do this since we dont want to duplicate the \"/coco128/\" part twice in the final path.\n",
    "print(extraction_path)\n",
    "z.extractall(extraction_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d5636b3-8ede-46af-a89f-bd0ac0842ab5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[0m\u001B[01;32m'02_Computer Vision: YOLO Training Best Practice on Databricks - MultiNode-MultiGPU version'\u001B[0m\u001B[K*\r\n \u001B[01;32mcoco128.yaml\u001B[0m*\r\n \u001B[01;32mExperiments_YOLO_CoCo\u001B[0m*\r\n\u001B[01;32m'HIMSS_Demo_MedCellTypes - YOLO Training on Databricks - MultiNode-MultiGPU version'\u001B[0m\u001B[K*\r\n\u001B[01;32m'quick test yolo11n with coco128'\u001B[0m*\r\n \u001B[01;32msgc-mlflow3-iris-deeplearning\u001B[0m*\r\n \u001B[01;32myolo11n.pt\u001B[0m*\r\n \u001B[01;32myolo12n.pt\u001B[0m*\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce7e6010-1b3a-465a-995a-a794541cc5d0",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "also move coco128.yaml file to there"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'/Volumes/yyang/computer_vision/yolo/data/coco128.yaml'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %sh\n",
    "# mv ./coco128.yaml /Volumes/yyang/computer_vision/yolo/data/\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "data_yaml_path = f'{extraction_path}/coco128.yaml'\n",
    "print('data_yaml_path is:', data_yaml_path)\n",
    "\n",
    "if os.path.exists(data_yaml_path):\n",
    "    os.remove(data_yaml_path)\n",
    "shutil.move('./coco128.yaml', data_yaml_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7d829ce2-835a-4d9c-92fb-742c991e4a6e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Setup Mlflow Related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da48cc45-99f1-4959-a96a-d1ab35382f5c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import mlflow\n",
    "import torch.distributed as dist\n",
    "from ultralytics import settings\n",
    "from mlflow.types.schema import Schema, ColSpec\n",
    "from mlflow.models.signature import ModelSignature\n",
    "\n",
    "input_schema = Schema(\n",
    "    [\n",
    "        ColSpec(\"string\", \"image_source\"),\n",
    "    ]\n",
    ")\n",
    "output_schema = Schema([ColSpec(\"string\",\"class_name\"),\n",
    "                        ColSpec(\"integer\",\"class_num\"),\n",
    "                        ColSpec(\"double\",\"confidence\")]\n",
    "                       )\n",
    "\n",
    "signature = ModelSignature(inputs=input_schema, \n",
    "                           outputs=output_schema)\n",
    "\n",
    "# settings.update({\"mlflow\":False}) # Specifically, it disables the integration with MLflow. By setting the mlflow key to False, you are instructing the ultralytics library not to use MLflow for logging or tracking experiments.\n",
    "\n",
    "# ultralytics level setting with MLflow\n",
    "settings.update({\"mlflow\":True}) # if you do want to autolog.\n",
    "# # Config MLflow\n",
    "mlflow.autolog(disable=True)\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "659998a6-0118-4ca3-9e27-fab85a303cbb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLFLOW_ENABLE_SYSTEM_METRICS_LOGGING set to true\nMLFLOW_EXPERIMENT_NAME set to /Users/yang.yang@databricks.com/SGC_YOLO_Test/Experiments_YOLO_CoCo\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "experiment_name = \"/Users/yang.yang@databricks.com/SGC_YOLO_Test/Experiments_YOLO_CoCo\"\n",
    "\n",
    "os.environ['MLFLOW_ENABLE_SYSTEM_METRICS_LOGGING'] = \"true\"\n",
    "print(f\"MLFLOW_ENABLE_SYSTEM_METRICS_LOGGING set to {os.environ['MLFLOW_ENABLE_SYSTEM_METRICS_LOGGING']}\")\n",
    "\n",
    "os.environ['MLFLOW_EXPERIMENT_NAME'] = experiment_name\n",
    "print(f\"MLFLOW_EXPERIMENT_NAME set to {os.environ['MLFLOW_EXPERIMENT_NAME']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7114dd4c-32ed-4f43-912f-a54f597e9879",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/07 18:55:57 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n2025/10/07 18:55:57 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n2025/10/07 18:55:57 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Error =>  [Errno 2] No such file or directory: 'rocminfo'\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(experiment_name)\n",
    "experiment_id = mlflow.get_experiment_by_name(experiment_name).experiment_id\n",
    "\n",
    "# Reset MLFLOW_RUN_ID, so we dont bump into the wrong one.\n",
    "if 'MLFLOW_RUN_ID' in os.environ:\n",
    "    del os.environ['MLFLOW_RUN_ID']\n",
    "\n",
    "with mlflow.start_run(experiment_id=experiment_id) as parent_run:\n",
    "    active_run_id = mlflow.last_active_run().info.run_id\n",
    "    active_run_name = mlflow.last_active_run().info.run_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9cb51d8-ee01-4a8f-acda-920d46ab7023",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/yang.yang@databricks.com/SGC_YOLO_Test/Experiments_YOLO_CoCo 2518420765913308 7394f74914aa4015a64c061c989cf7ef\n"
     ]
    }
   ],
   "source": [
    "print(experiment_name, experiment_id, active_run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b17a6ea3-d611-4f79-9546-463b7941191e",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "test if loadable"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "YOLO(\n",
       "  (model): DetectionModel(\n",
       "    (model): Sequential(\n",
       "      (0): Conv(\n",
       "        (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv(\n",
       "        (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (2): C3k2(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(48, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(8, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): Conv(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (4): C3k2(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): Conv(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (6): C3k2(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): C3k(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv3): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (m): Sequential(\n",
       "              (0): Bottleneck(\n",
       "                (cv1): Conv(\n",
       "                  (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (cv2): Conv(\n",
       "                  (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "              (1): Bottleneck(\n",
       "                (cv1): Conv(\n",
       "                  (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (cv2): Conv(\n",
       "                  (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): Conv(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (8): C3k2(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): C3k(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv3): Conv(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (m): Sequential(\n",
       "              (0): Bottleneck(\n",
       "                (cv1): Conv(\n",
       "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (cv2): Conv(\n",
       "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "              (1): Bottleneck(\n",
       "                (cv1): Conv(\n",
       "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (cv2): Conv(\n",
       "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): SPPF(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (10): C2PSA(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): Sequential(\n",
       "          (0): PSABlock(\n",
       "            (attn): Attention(\n",
       "              (qkv): Conv(\n",
       "                (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): Identity()\n",
       "              )\n",
       "              (proj): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): Identity()\n",
       "              )\n",
       "              (pe): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): Identity()\n",
       "              )\n",
       "            )\n",
       "            (ffn): Sequential(\n",
       "              (0): Conv(\n",
       "                (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv(\n",
       "                (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): Identity()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      (12): Concat()\n",
       "      (13): C3k2(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (14): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      (15): Concat()\n",
       "      (16): C3k2(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (17): Conv(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (18): Concat()\n",
       "      (19): C3k2(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (20): Conv(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (21): Concat()\n",
       "      (22): C3k2(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): C3k(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv3): Conv(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (m): Sequential(\n",
       "              (0): Bottleneck(\n",
       "                (cv1): Conv(\n",
       "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (cv2): Conv(\n",
       "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "              (1): Bottleneck(\n",
       "                (cv1): Conv(\n",
       "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (cv2): Conv(\n",
       "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (23): Detect(\n",
       "        (cv2): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (cv3): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): DWConv(\n",
       "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv(\n",
       "                (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Sequential(\n",
       "              (0): DWConv(\n",
       "                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)\n",
       "                (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv(\n",
       "                (conv): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): DWConv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv(\n",
       "                (conv): Conv2d(128, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Sequential(\n",
       "              (0): DWConv(\n",
       "                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)\n",
       "                (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv(\n",
       "                (conv): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): DWConv(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "                (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv(\n",
       "                (conv): Conv2d(256, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Sequential(\n",
       "              (0): DWConv(\n",
       "                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)\n",
       "                (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv(\n",
       "                (conv): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (dfl): DFL(\n",
       "          (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YOLO(\"yolo11n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76050ba2-5a74-4804-a5a7-98e607a17586",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "(optional) if you need to manually give the yaml path"
    }
   },
   "outputs": [],
   "source": [
    "# data_yaml_path = \"./coco128.yaml\" # ref: https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/datasets/coco128.yaml\n",
    "\n",
    "data_yaml_path = '/Volumes/yyang/computer_vision/yolo/data/coco128.yaml'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e2ce4204-8ab8-41ba-83f0-6ef73d992ed0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Start to Train using SGC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d9ac468-04cd-4bcb-8b2c-525a5a114bed",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "helper functions"
    }
   },
   "outputs": [],
   "source": [
    "def setup():\n",
    "    \"\"\"Initialize the distributed training process group\"\"\"\n",
    "    # Check if we're in a distributed environment\n",
    "    if 'RANK' in os.environ and 'WORLD_SIZE' in os.environ:\n",
    "        rank = int(os.environ['RANK'])\n",
    "        world_size = int(os.environ['WORLD_SIZE'])\n",
    "        local_rank = int(os.environ.get('LOCAL_RANK', 0))\n",
    "    else:\n",
    "        # Fallback for single GPU\n",
    "        rank = 0\n",
    "        world_size = 1\n",
    "        local_rank = 0\n",
    "\n",
    "    # Initialize process group\n",
    "    if world_size > 1:\n",
    "        if not dist.is_initialized():\n",
    "            dist.init_process_group(backend='nccl', rank=rank, world_size=world_size)\n",
    "\n",
    "    # Set device\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(f'cuda:{local_rank}')\n",
    "        torch.cuda.set_device(device)\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "\n",
    "    return rank, world_size, device\n",
    "  \n",
    "def cleanup():\n",
    "    \"\"\"Clean up the distributed training process group\"\"\"\n",
    "    if dist.is_initialized():\n",
    "        dist.destroy_process_group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d142d022-f643-4279-ac01-37626f5ba276",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "single local gpu test with minimal example"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.206 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\nSearching for 1 idle GPUs with free memory >= 20.0% and free utilization >= 0.0%...\nSelected idle CUDA devices [0]\nUltralytics 8.3.204 ğŸš€ Python-3.12.3 torch-2.7.1+cu126 CUDA:0 (NVIDIA A10G, 22503MiB)\n\u001B[34m\u001B[1mengine/trainer: \u001B[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/Volumes/yyang/computer_vision/yolo/data/coco128.yaml, degrees=0.45, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=True, fliplr=1, flipud=1, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/Volumes/yyang/computer_vision/yolo//raw_model/yolo11n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.001, plots=True, pose=12.0, pretrained=True, profile=False, project=/tmp/training_results/, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/tmp/training_results/train, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n\r\u001B[KDownloading https://ultralytics.com/assets/Arial.ttf to '/tmp/Ultralytics/Arial.ttf': 100% â”â”â”â”â”â”â”â”â”â”â”â” 755.1KB 15.1MB/s 0.0s\r\u001B[KDownloading https://ultralytics.com/assets/Arial.ttf to '/tmp/Ultralytics/Arial.ttf': 100% â”â”â”â”â”â”â”â”â”â”â”â” 755.1KB 14.9MB/s 0.0s\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n 23        [16, 19, 22]  1    464912  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \nYOLO11n summary: 181 layers, 2,624,080 parameters, 2,624,064 gradients, 6.6 GFLOPs\n\nTransferred 499/499 items from pretrained weights\nFreezing layer 'model.23.dfl.conv.weight'\n\u001B[34m\u001B[1mAMP: \u001B[0mrunning Automatic Mixed Precision (AMP) checks...\n\u001B[34m\u001B[1mAMP: \u001B[0mchecks passed âœ…\n\u001B[34m\u001B[1mtrain: \u001B[0mFast image access âœ… (ping: 2.4Â±0.1 ms, read: 1.0Â±0.4 MB/s, size: 46.0 KB)\n\r\u001B[K\u001B[34m\u001B[1mtrain: \u001B[0mScanning /.fuse-mounts/Volumes/yyang/computer_vision/yolo/data/coco128/labels/train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 128/128 24.4Mit/s 0.0s\r\u001B[K\u001B[34m\u001B[1mtrain: \u001B[0mScanning /.fuse-mounts/Volumes/yyang/computer_vision/yolo/data/coco128/labels/train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 128/128 205.2Kit/s 0.0s\n\u001B[34m\u001B[1mval: \u001B[0mFast image access âœ… (ping: 5.7Â±5.7 ms, read: 4.7Â±8.5 MB/s, size: 56.4 KB)\n\r\u001B[K\u001B[34m\u001B[1mval: \u001B[0mScanning /.fuse-mounts/Volumes/yyang/computer_vision/yolo/data/coco128/labels/train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 128/128 3.1Mit/s 0.0s\r\u001B[K\u001B[34m\u001B[1mval: \u001B[0mScanning /.fuse-mounts/Volumes/yyang/computer_vision/yolo/data/coco128/labels/train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 128/128 106.2Kit/s 0.0s\nPlotting labels to /tmp/training_results/train/labels.jpg... \n\u001B[34m\u001B[1moptimizer:\u001B[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001B[34m\u001B[1moptimizer:\u001B[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/07 19:21:33 DEBUG mlflow.utils.autologging_utils: Called autolog() method for mlflow autologging with args '()' and kwargs '{'log_input_examples': False, 'log_model_signatures': True, 'log_models': True, 'log_datasets': True, 'log_traces': True, 'disable': False, 'exclusive': False, 'disable_for_unsupported_versions': False, 'silent': False, 'extra_tags': None, 'exclude_flavors': None}'\n2025/10/07 19:21:33 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mMLflow: \u001B[0mlogging run_id(b9c11b08c1b74cf99f811cd9bc0a0100) to databricks\n\u001B[34m\u001B[1mMLflow: \u001B[0mdisable with 'yolo settings mlflow=False'\nImage sizes 640 train, 640 val\nUsing 8 dataloader workers\nLogging results to \u001B[1m/tmp/training_results/train\u001B[0m\nStarting training for 20 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\r\u001B[K       1/20      2.34G      1.871      2.457      1.764        164        640: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/8  0.8s\r\u001B[K       1/20      2.54G      1.899      2.873      1.836        210        640: 12% â”â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/8 2.2it/s 1.0s<3.2s\r\u001B[K       1/20      2.62G      1.947      2.912      1.859        144        640: 25% â”â”â”â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2/8 2.6it/s 1.3s<2.3s\r\u001B[K       1/20      2.62G      1.982      2.949      1.822        209        640: 38% â”â”â”â”â”€â”€â”€â”€â”€â”€â”€â”€ 3/8 3.1it/s 1.5s<1.6s\r\u001B[K       1/20      2.62G      2.006      2.929      1.866        166        640: 50% â”â”â”â”â”â”â”€â”€â”€â”€â”€â”€ 4/8 4.8it/s 1.6s<0.8s\r\u001B[K       1/20      2.62G      2.013      3.075      1.848        218        640: 62% â”â”â”â”â”â”â”â”€â”€â”€â”€â”€ 5/8 4.8it/s 1.8s<0.6s\r\u001B[K       1/20      2.64G      2.019      3.059      1.844        224        640: 75% â”â”â”â”â”â”â”â”â”â”€â”€â”€ 6/8 5.8it/s 1.9s<0.3s\r\u001B[K       1/20      2.64G      2.044      3.102      1.871        160        640: 88% â”â”â”â”â”â”â”â”â”â”â”€â”€ 7/8 6.6it/s 2.0s<0.2s\r\u001B[K       1/20      2.64G      2.044      3.102      1.871        160        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.9it/s 2.0s\r\u001B[K       1/20      2.64G      2.044      3.102      1.871        160        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.9it/s 2.0s\n\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 25% â”â”â”â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/4 0.0it/s 6.5s<1:05\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 50% â”â”â”â”â”â”â”€â”€â”€â”€â”€â”€ 2/4 1.1it/s 6.8s<1.8s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 75% â”â”â”â”â”â”â”â”â”â”€â”€â”€ 3/4 2.1it/s 7.1s<0.5s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.5it/s 7.3s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.5it/s 7.3s\n                   all        128        929      0.675      0.595      0.678      0.512\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\r\u001B[K       2/20      3.64G      1.931      3.189      1.747        236        640: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/8  0.1s\r\u001B[K       2/20      3.64G       1.86      3.049       1.75        192        640: 12% â”â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/8 2.5it/s 0.2s<2.8s\r\u001B[K       2/20      3.64G       1.86      2.972       1.71        303        640: 25% â”â”â”â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2/8 4.3it/s 0.4s<1.4s\r\u001B[K       2/20      3.64G      1.834      2.927        1.7        247        640: 38% â”â”â”â”â”€â”€â”€â”€â”€â”€â”€â”€ 3/8 5.5it/s 0.5s<0.9s\r\u001B[K       2/20      3.64G      1.847      2.921      1.699        241        640: 50% â”â”â”â”â”â”â”€â”€â”€â”€â”€â”€ 4/8 6.3it/s 0.6s<0.6s\r\u001B[K       2/20      3.64G      1.878      2.896      1.702        198        640: 62% â”â”â”â”â”â”â”â”€â”€â”€â”€â”€ 5/8 6.9it/s 0.7s<0.4s\r\u001B[K       2/20      3.64G       1.87      2.931      1.694        222        640: 75% â”â”â”â”â”â”â”â”â”â”€â”€â”€ 6/8 7.3it/s 0.8s<0.3s\r\u001B[K       2/20      3.64G      1.884      3.017      1.733        194        640: 88% â”â”â”â”â”â”â”â”â”â”â”€â”€ 7/8 7.6it/s 1.0s<0.1s\r\u001B[K       2/20      3.64G      1.884      3.017      1.733        194        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 8.3it/s 1.0s\r\u001B[K       2/20      3.64G      1.884      3.017      1.733        194        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 8.3it/s 1.0s\n\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 25% â”â”â”â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/4 2.6it/s 0.1s<1.2s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 50% â”â”â”â”â”â”â”€â”€â”€â”€â”€â”€ 2/4 4.3it/s 0.2s<0.5s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 75% â”â”â”â”â”â”â”â”â”â”€â”€â”€ 3/4 5.4it/s 0.4s<0.2s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 8.2it/s 0.5s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 8.2it/s 0.5s\n                   all        128        929      0.699      0.596      0.677      0.501\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\r\u001B[K       3/20      3.65G      1.771      2.807      1.673        240        640: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/8  0.1s\r\u001B[K       3/20      3.66G      1.884      2.704      1.718        230        640: 25% â”â”â”â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2/8 2.8it/s 0.3s<2.2s\r\u001B[K       3/20      3.66G      1.843      2.634      1.694        236        640: 50% â”â”â”â”â”â”â”€â”€â”€â”€â”€â”€ 4/8 4.7it/s 0.5s<0.8s\r\u001B[K       3/20      3.66G      1.824      2.668       1.67        199        640: 75% â”â”â”â”â”â”â”â”â”â”€â”€â”€ 6/8 6.0it/s 0.8s<0.3s\r\u001B[K       3/20      3.66G      1.832      2.735      1.691        243        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 9.3it/s 0.9s\r\u001B[K       3/20      3.66G      1.832      2.735      1.691        243        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 9.2it/s 0.9s\n\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 25% â”â”â”â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/4 2.6it/s 0.1s<1.2s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 50% â”â”â”â”â”â”â”€â”€â”€â”€â”€â”€ 2/4 4.1it/s 0.2s<0.5s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 75% â”â”â”â”â”â”â”â”â”â”€â”€â”€ 3/4 5.1it/s 0.4s<0.2s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 7.9it/s 0.5s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 7.9it/s 0.5s\n                   all        128        929      0.679      0.596      0.669      0.486\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\r\u001B[K       4/20      3.68G      1.896       2.83      1.697        174        640: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/8  0.1s\r\u001B[K       4/20      3.68G      1.778      2.729      1.685        157        640: 25% â”â”â”â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2/8 2.7it/s 0.3s<2.2s\r\u001B[K       4/20      3.68G      1.836       2.68      1.674        250        640: 50% â”â”â”â”â”â”â”€â”€â”€â”€â”€â”€ 4/8 4.7it/s 0.6s<0.9s\r\u001B[K       4/20      3.68G      1.849      2.676       1.69        183        640: 75% â”â”â”â”â”â”â”â”â”â”€â”€â”€ 6/8 6.0it/s 0.8s<0.3s\r\u001B[K       4/20      3.68G       1.85      2.708      1.702        248        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 9.1it/s 0.9s\r\u001B[K       4/20      3.68G       1.85      2.708      1.702        248        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 9.1it/s 0.9s\n\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 25% â”â”â”â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/4 2.4it/s 0.1s<1.2s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 50% â”â”â”â”â”â”â”€â”€â”€â”€â”€â”€ 2/4 4.2it/s 0.2s<0.5s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 75% â”â”â”â”â”â”â”â”â”â”€â”€â”€ 3/4 5.0it/s 0.4s<0.2s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 7.7it/s 0.5s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 7.7it/s 0.5s\n                   all        128        929      0.671        0.6      0.675      0.479\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\r\u001B[K       5/20      3.68G      1.882      2.454      1.669        315        640: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/8  0.1s\r\u001B[K       5/20      3.68G      1.772      2.407      1.697        145        640: 25% â”â”â”â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2/8 2.8it/s 0.3s<2.1s\r\u001B[K       5/20      3.68G       1.73      2.309      1.671        189        640: 50% â”â”â”â”â”â”â”€â”€â”€â”€â”€â”€ 4/8 4.8it/s 0.6s<0.8s\r\u001B[K       5/20      3.68G      1.731       2.34      1.658        267        640: 62% â”â”â”â”â”â”â”â”€â”€â”€â”€â”€ 5/8 6.3it/s 0.7s<0.5s\r\u001B[K       5/20      3.68G      1.734      2.336      1.657        199        640: 75% â”â”â”â”â”â”â”â”â”â”€â”€â”€ 6/8 6.9it/s 0.8s<0.3s\r\u001B[K       5/20      3.68G      1.738      2.374      1.651        275        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 9.2it/s 0.9s\r\u001B[K       5/20      3.68G      1.738      2.374      1.651        275        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 9.2it/s 0.9s\n\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 25% â”â”â”â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/4 2.6it/s 0.1s<1.2s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 50% â”â”â”â”â”â”â”€â”€â”€â”€â”€â”€ 2/4 4.2it/s 0.2s<0.5s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 75% â”â”â”â”â”â”â”â”â”â”€â”€â”€ 3/4 5.2it/s 0.4s<0.2s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 7.9it/s 0.5s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 7.9it/s 0.5s\n                   all        128        929      0.706      0.586      0.673      0.461\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\r\u001B[K       6/20      3.69G      1.695      2.116      1.625        156        640: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/8  0.1s\r\u001B[K       6/20      3.69G       1.69      2.296      1.633        184        640: 25% â”â”â”â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2/8 2.7it/s 0.4s<2.2s\r\u001B[K       6/20      3.69G      1.655      2.237      1.604        237        640: 50% â”â”â”â”â”â”â”€â”€â”€â”€â”€â”€ 4/8 4.6it/s 0.6s<0.9s\r\u001B[K       6/20      3.69G      1.686      2.342      1.591        188        640: 75% â”â”â”â”â”â”â”â”â”â”€â”€â”€ 6/8 6.0it/s 0.8s<0.3s\r\u001B[K       6/20      3.69G      1.697      2.326      1.592        255        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 9.0it/s 0.9s\r\u001B[K       6/20      3.69G      1.697      2.326      1.592        255        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 8.9it/s 0.9s\n\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 25% â”â”â”â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/4 2.5it/s 0.1s<1.2s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 50% â”â”â”â”â”â”â”€â”€â”€â”€â”€â”€ 2/4 4.2it/s 0.2s<0.5s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 75% â”â”â”â”â”â”â”â”â”â”€â”€â”€ 3/4 5.2it/s 0.4s<0.2s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 7.8it/s 0.5s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 7.8it/s 0.5s\n                   all        128        929      0.714      0.573      0.665      0.439\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\r\u001B[K       7/20      3.69G      1.786      2.273      1.614        195        640: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/8  0.1s\r\u001B[K       7/20      3.69G      1.754      2.164      1.585        175        640: 25% â”â”â”â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2/8 2.9it/s 0.3s<2.1s\r\u001B[K       7/20      3.69G       1.69      2.155      1.571        166        640: 50% â”â”â”â”â”â”â”€â”€â”€â”€â”€â”€ 4/8 5.3it/s 0.5s<0.8s\r\u001B[K       7/20      3.69G      1.707       2.22      1.585        184        640: 62% â”â”â”â”â”â”â”â”€â”€â”€â”€â”€ 5/8 6.2it/s 0.6s<0.5s\r\u001B[K       7/20      3.69G      1.698      2.253       1.59        280        640: 88% â”â”â”â”â”â”â”â”â”â”â”€â”€ 7/8 7.5it/s 0.8s<0.1s\r\u001B[K       7/20      3.69G      1.698      2.253       1.59        280        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 9.7it/s 0.8s\r\u001B[K       7/20      3.69G      1.698      2.253       1.59        280        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 9.7it/s 0.8s\n\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 25% â”â”â”â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/4 2.6it/s 0.1s<1.2s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 50% â”â”â”â”â”â”â”€â”€â”€â”€â”€â”€ 2/4 4.1it/s 0.2s<0.5s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 75% â”â”â”â”â”â”â”â”â”â”€â”€â”€ 3/4 5.1it/s 0.4s<0.2s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 7.8it/s 0.5s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 7.8it/s 0.5s\n                   all        128        929      0.678      0.594      0.668      0.434\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\r\u001B[K       8/20      3.71G      1.741      2.207      1.638        183        640: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/8  0.1s\r\u001B[K       8/20      3.71G      1.665      2.196      1.576        203        640: 25% â”â”â”â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2/8 3.2it/s 0.3s<1.9s\r\u001B[K       8/20      3.71G      1.703      2.168      1.602        266        640: 38% â”â”â”â”â”€â”€â”€â”€â”€â”€â”€â”€ 3/8 4.8it/s 0.4s<1.0s\r\u001B[K       8/20      3.71G      1.712      2.109      1.593        225        640: 62% â”â”â”â”â”â”â”â”€â”€â”€â”€â”€ 5/8 6.6it/s 0.6s<0.5s\r\u001B[K       8/20      3.71G      1.727      2.143      1.592        219        640: 75% â”â”â”â”â”â”â”â”â”â”€â”€â”€ 6/8 7.1it/s 0.7s<0.3s\r\u001B[K       8/20      3.71G      1.709      2.098      1.582        202        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 9.6it/s 0.8s\r\u001B[K       8/20      3.71G      1.709      2.098      1.582        202        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 9.6it/s 0.8s\n\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 25% â”â”â”â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/4 2.3it/s 0.1s<1.3s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 50% â”â”â”â”â”â”â”€â”€â”€â”€â”€â”€ 2/4 3.9it/s 0.3s<0.5s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 75% â”â”â”â”â”â”â”â”â”â”€â”€â”€ 3/4 4.8it/s 0.4s<0.2s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 7.5it/s 0.5s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 7.5it/s 0.5s\n                   all        128        929      0.658      0.606      0.659      0.418\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\r\u001B[K       9/20      3.72G      1.697      2.253      1.559        269        640: 12% â”â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/8 1.4it/s 0.2s<5.1s\r\u001B[K       9/20      3.72G      1.654      2.128      1.506        252        640: 38% â”â”â”â”â”€â”€â”€â”€â”€â”€â”€â”€ 3/8 4.0it/s 0.4s<1.3s\r\u001B[K       9/20      3.72G      1.669      2.111      1.521        281        640: 50% â”â”â”â”â”â”â”€â”€â”€â”€â”€â”€ 4/8 5.2it/s 0.5s<0.8s\r\u001B[K       9/20      3.72G      1.666      2.112      1.538        214        640: 75% â”â”â”â”â”â”â”â”â”â”€â”€â”€ 6/8 6.8it/s 0.7s<0.3s\r\u001B[K       9/20      3.72G      1.686      2.117      1.549        208        640: 88% â”â”â”â”â”â”â”â”â”â”â”€â”€ 7/8 7.2it/s 0.9s<0.1s\r\u001B[K       9/20      3.72G      1.686      2.117      1.549        208        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 9.4it/s 0.9s\r\u001B[K       9/20      3.72G      1.686      2.117      1.549        208        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 9.3it/s 0.9s\n\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 25% â”â”â”â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/4 0.2it/s 1.3s<13.4s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 50% â”â”â”â”â”â”â”€â”€â”€â”€â”€â”€ 2/4 2.4it/s 1.5s<0.8s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 75% â”â”â”â”â”â”â”â”â”â”€â”€â”€ 3/4 3.6it/s 1.6s<0.3s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 2.2it/s 1.8s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 2.2it/s 1.8s\n                   all        128        929      0.641      0.611      0.655      0.416\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\r\u001B[K      10/20      3.72G      1.544      2.064      1.497        157        640: 12% â”â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/8 1.6it/s 0.2s<4.4s\r\u001B[K      10/20      3.72G      1.521       1.97      1.472        203        640: 25% â”â”â”â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2/8 3.6it/s 0.3s<1.7s\r\u001B[K      10/20      3.72G      1.565      1.975      1.484        223        640: 50% â”â”â”â”â”â”â”€â”€â”€â”€â”€â”€ 4/8 5.7it/s 0.5s<0.7s\r\u001B[K      10/20      3.72G      1.543      1.939      1.476        253        640: 62% â”â”â”â”â”â”â”â”€â”€â”€â”€â”€ 5/8 6.4it/s 0.6s<0.5s\r\u001B[K      10/20      3.72G      1.539      1.913       1.47        227        640: 75% â”â”â”â”â”â”â”â”â”â”€â”€â”€ 6/8 7.4it/s 0.7s<0.3s\r\u001B[K      10/20      3.72G      1.557      1.932      1.481        220        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 9.8it/s 0.8s\r\u001B[K      10/20      3.72G      1.557      1.932      1.481        220        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 9.8it/s 0.8s\n\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 25% â”â”â”â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/4 2.6it/s 0.1s<1.2s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 50% â”â”â”â”â”â”â”€â”€â”€â”€â”€â”€ 2/4 4.2it/s 0.2s<0.5s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 75% â”â”â”â”â”â”â”â”â”â”€â”€â”€ 3/4 5.2it/s 0.4s<0.2s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 7.9it/s 0.5s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 7.9it/s 0.5s\n                   all        128        929      0.639      0.605      0.651      0.416\nClosing dataloader mosaic\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\r\u001B[K      11/20      3.72G      1.452      1.862      1.313         90        640: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/8  5.3s\r\u001B[K      11/20      3.72G      1.374        1.8      1.314         98        640: 12% â”â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/8 2.7it/s 5.4s<2.5s\r\u001B[K      11/20      3.72G      1.466      1.875      1.389        116        640: 25% â”â”â”â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2/8 3.8it/s 5.5s<1.6s\r\u001B[K      11/20      3.72G      1.486      1.947       1.39        131        640: 38% â”â”â”â”â”€â”€â”€â”€â”€â”€â”€â”€ 3/8 3.9it/s 5.8s<1.3s\r\u001B[K      11/20      3.72G      1.461      1.939      1.376        130        640: 50% â”â”â”â”â”â”â”€â”€â”€â”€â”€â”€ 4/8 3.5it/s 6.2s<1.2s\r\u001B[K      11/20      3.72G      1.497       1.91      1.414        108        640: 62% â”â”â”â”â”â”â”â”€â”€â”€â”€â”€ 5/8 4.5it/s 6.3s<0.7s\r\u001B[K      11/20      3.72G      1.534       1.93      1.465         85        640: 88% â”â”â”â”â”â”â”â”â”â”â”€â”€ 7/8 6.0it/s 6.5s<0.2s\r\u001B[K      11/20      3.72G      1.534       1.93      1.465         85        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 1.2it/s 6.5s\r\u001B[K      11/20      3.72G      1.534       1.93      1.465         85        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 1.2it/s 6.5s\n\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 25% â”â”â”â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/4 2.4it/s 0.1s<1.2s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 50% â”â”â”â”â”â”â”€â”€â”€â”€â”€â”€ 2/4 4.1it/s 0.2s<0.5s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 75% â”â”â”â”â”â”â”â”â”â”€â”€â”€ 3/4 5.1it/s 0.4s<0.2s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 7.8it/s 0.5s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 7.8it/s 0.5s\n                   all        128        929      0.662      0.603      0.659      0.427\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\r\u001B[K      12/20      3.72G       1.42      2.118      1.487         71        640: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/8  3.0s\r\u001B[K      12/20      3.72G      1.456      1.929      1.508         80        640: 12% â”â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/8 0.9it/s 3.4s<8.0s\r\u001B[K      12/20      3.72G      1.508      2.083      1.558        108        640: 25% â”â”â”â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2/8 1.8it/s 3.6s<3.3s\r\u001B[K      12/20      3.72G      1.513      2.085      1.521         88        640: 38% â”â”â”â”â”€â”€â”€â”€â”€â”€â”€â”€ 3/8 2.9it/s 3.8s<1.7s\r\u001B[K      12/20      3.72G       1.51      2.066      1.505        126        640: 50% â”â”â”â”â”â”â”€â”€â”€â”€â”€â”€ 4/8 2.9it/s 4.1s<1.4s\r\u001B[K      12/20      3.72G      1.559      2.022      1.509        138        640: 75% â”â”â”â”â”â”â”â”â”â”€â”€â”€ 6/8 5.3it/s 4.3s<0.4s\r\u001B[K      12/20      3.72G      1.547      1.976      1.486        116        640: 88% â”â”â”â”â”â”â”â”â”â”â”€â”€ 7/8 6.2it/s 4.4s<0.2s\r\u001B[K      12/20      3.72G      1.547      1.976      1.486        116        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 1.8it/s 4.4s\r\u001B[K      12/20      3.72G      1.547      1.976      1.486        116        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 1.8it/s 4.4s\n\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 25% â”â”â”â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/4 2.5it/s 0.1s<1.2s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 50% â”â”â”â”â”â”â”€â”€â”€â”€â”€â”€ 2/4 4.1it/s 0.2s<0.5s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 75% â”â”â”â”â”â”â”â”â”â”€â”€â”€ 3/4 5.2it/s 0.4s<0.2s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 7.9it/s 0.5s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 7.9it/s 0.5s\n                   all        128        929      0.658       0.59       0.66      0.427\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\r\u001B[K      13/20      3.72G      1.519      1.519      1.554        130        640: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/8  2.0s\r\u001B[K      13/20      3.72G      1.553      1.667      1.454        118        640: 12% â”â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/8 1.1it/s 2.3s<6.2s\r\u001B[K      13/20      3.72G      1.647      1.957      1.487        138        640: 38% â”â”â”â”â”€â”€â”€â”€â”€â”€â”€â”€ 3/8 3.7it/s 2.5s<1.4s\r\u001B[K      13/20      3.72G      1.599      1.941      1.476         85        640: 50% â”â”â”â”â”â”â”€â”€â”€â”€â”€â”€ 4/8 3.0it/s 3.2s<1.3s\r\u001B[K      13/20      3.72G       1.59      1.886      1.481        106        640: 62% â”â”â”â”â”â”â”â”€â”€â”€â”€â”€ 5/8 3.2it/s 3.5s<0.9s\r\u001B[K      13/20      3.72G      1.582      1.862      1.472        101        640: 88% â”â”â”â”â”â”â”â”â”â”â”€â”€ 7/8 4.5it/s 3.7s<0.2s\r\u001B[K      13/20      3.72G      1.582      1.862      1.472        101        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 2.2it/s 3.7s\r\u001B[K      13/20      3.72G      1.582      1.862      1.472        101        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 2.2it/s 3.7s\n\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 25% â”â”â”â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/4 2.3it/s 0.1s<1.3s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 50% â”â”â”â”â”â”â”€â”€â”€â”€â”€â”€ 2/4 3.2it/s 0.3s<0.6s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 75% â”â”â”â”â”â”â”â”â”â”€â”€â”€ 3/4 4.4it/s 0.5s<0.2s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 6.8it/s 0.6s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 6.8it/s 0.6s\n                   all        128        929      0.673      0.597      0.661      0.424\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\r\u001B[K      14/20      3.72G      1.586      1.787      1.445        111        640: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/8  1.9s\r\u001B[K      14/20      3.72G      1.606       1.75      1.398        173        640: 12% â”â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/8 2.2it/s 2.0s<3.1s\r\u001B[K      14/20      3.72G      1.613      1.788      1.464        141        640: 25% â”â”â”â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2/8 3.5it/s 2.2s<1.7s\r\u001B[K      14/20      3.72G      1.572      1.757      1.493        104        640: 38% â”â”â”â”â”€â”€â”€â”€â”€â”€â”€â”€ 3/8 4.2it/s 2.3s<1.2s\r\u001B[K      14/20      3.72G      1.533      1.732      1.477         81        640: 50% â”â”â”â”â”â”â”€â”€â”€â”€â”€â”€ 4/8 5.2it/s 2.5s<0.8s\r\u001B[K      14/20      3.72G      1.518      1.729       1.47         93        640: 62% â”â”â”â”â”â”â”â”€â”€â”€â”€â”€ 5/8 5.9it/s 2.6s<0.5s\r\u001B[K      14/20      3.72G      1.534      1.745      1.462         83        640: 75% â”â”â”â”â”â”â”â”â”â”€â”€â”€ 6/8 6.5it/s 2.7s<0.3s\r\u001B[K      14/20      3.72G      1.512      1.715      1.465        100        640: 88% â”â”â”â”â”â”â”â”â”â”â”€â”€ 7/8 6.3it/s 2.9s<0.2s\r\u001B[K      14/20      3.72G      1.512      1.715      1.465        100        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 2.8it/s 2.9s\r\u001B[K      14/20      3.72G      1.512      1.715      1.465        100        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 2.8it/s 2.9s\n\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 25% â”â”â”â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/4 1.7it/s 0.2s<1.7s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 50% â”â”â”â”â”â”â”€â”€â”€â”€â”€â”€ 2/4 2.9it/s 0.4s<0.7s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 75% â”â”â”â”â”â”â”â”â”â”€â”€â”€ 3/4 3.6it/s 0.5s<0.3s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 5.6it/s 0.7s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 5.6it/s 0.7s\n                   all        128        929      0.671      0.601      0.664       0.43\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\r\u001B[K      15/20      3.72G      1.348       1.51       1.33         68        640: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/8  0.9s\r\u001B[K      15/20      3.72G      1.348      1.601      1.402         57        640: 25% â”â”â”â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2/8 3.2it/s 1.1s<1.9s\r\u001B[K      15/20      3.72G      1.337      1.562      1.385         90        640: 38% â”â”â”â”â”€â”€â”€â”€â”€â”€â”€â”€ 3/8 4.7it/s 1.2s<1.1s\r\u001B[K      15/20      3.72G       1.41      1.607        1.4        174        640: 62% â”â”â”â”â”â”â”â”€â”€â”€â”€â”€ 5/8 6.5it/s 1.4s<0.5s\r\u001B[K      15/20      3.72G      1.444      1.675       1.41        109        640: 88% â”â”â”â”â”â”â”â”â”â”â”€â”€ 7/8 7.2it/s 1.6s<0.1s\r\u001B[K      15/20      3.72G      1.444      1.675       1.41        109        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 5.0it/s 1.6s\r\u001B[K      15/20      3.72G      1.444      1.675       1.41        109        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 5.0it/s 1.6s\n\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 25% â”â”â”â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/4 2.5it/s 0.1s<1.2s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 50% â”â”â”â”â”â”â”€â”€â”€â”€â”€â”€ 2/4 4.1it/s 0.2s<0.5s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 75% â”â”â”â”â”â”â”â”â”â”€â”€â”€ 3/4 5.1it/s 0.4s<0.2s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 7.8it/s 0.5s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 7.8it/s 0.5s\n                   all        128        929      0.688      0.594      0.667      0.434\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\r\u001B[K      16/20      3.72G      1.331      1.466      1.268        103        640: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/8  1.5s\r\u001B[K      16/20      3.72G      1.409      1.613      1.351        100        640: 12% â”â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/8 2.5it/s 1.7s<2.8s\r\u001B[K      16/20      3.72G      1.461      1.786      1.404        116        640: 38% â”â”â”â”â”€â”€â”€â”€â”€â”€â”€â”€ 3/8 4.5it/s 1.9s<1.1s\r\u001B[K      16/20      3.72G       1.49      1.733      1.415        139        640: 62% â”â”â”â”â”â”â”â”€â”€â”€â”€â”€ 5/8 6.3it/s 2.1s<0.5s\r\u001B[K      16/20      3.72G      1.467      1.706      1.417        137        640: 88% â”â”â”â”â”â”â”â”â”â”â”€â”€ 7/8 7.2it/s 2.3s<0.1s\r\u001B[K      16/20      3.72G      1.467      1.706      1.417        137        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.5it/s 2.3s\r\u001B[K      16/20      3.72G      1.467      1.706      1.417        137        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.5it/s 2.3s\n\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 25% â”â”â”â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/4 2.4it/s 0.1s<1.2s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 50% â”â”â”â”â”â”â”€â”€â”€â”€â”€â”€ 2/4 4.2it/s 0.2s<0.5s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 75% â”â”â”â”â”â”â”â”â”â”€â”€â”€ 3/4 4.8it/s 0.4s<0.2s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 7.1it/s 0.6s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 7.0it/s 0.6s\n                   all        128        929      0.704      0.593      0.666      0.436\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\r\u001B[K      17/20      3.72G      1.441      1.734      1.463        139        640: 12% â”â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/8 1.6it/s 0.2s<4.4s\r\u001B[K      17/20      3.72G      1.426      1.711      1.456        135        640: 38% â”â”â”â”â”€â”€â”€â”€â”€â”€â”€â”€ 3/8 2.9it/s 0.5s<1.7s\r\u001B[K      17/20      3.72G      1.459       1.71      1.438        131        640: 50% â”â”â”â”â”â”â”€â”€â”€â”€â”€â”€ 4/8 4.3it/s 0.6s<0.9s\r\u001B[K      17/20      3.72G      1.428      1.661      1.411        109        640: 62% â”â”â”â”â”â”â”â”€â”€â”€â”€â”€ 5/8 5.2it/s 0.8s<0.6s\r\u001B[K      17/20      3.72G      1.438       1.66      1.425        127        640: 75% â”â”â”â”â”â”â”â”â”â”€â”€â”€ 6/8 4.2it/s 1.3s<0.5s\r\u001B[K      17/20      3.72G      1.456      1.662      1.441         91        640: 88% â”â”â”â”â”â”â”â”â”â”â”€â”€ 7/8 5.1it/s 1.5s<0.2s\r\u001B[K      17/20      3.72G      1.456      1.662      1.441         91        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 5.5it/s 1.5s\r\u001B[K      17/20      3.72G      1.456      1.662      1.441         91        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 5.5it/s 1.5s\n\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 25% â”â”â”â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/4 2.6it/s 0.1s<1.2s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 50% â”â”â”â”â”â”â”€â”€â”€â”€â”€â”€ 2/4 4.1it/s 0.2s<0.5s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 75% â”â”â”â”â”â”â”â”â”â”€â”€â”€ 3/4 4.6it/s 0.4s<0.2s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 6.5it/s 0.6s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 6.5it/s 0.6s\n                   all        128        929      0.695      0.595       0.67      0.439\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\r\u001B[K      18/20      3.72G      1.445       1.71      1.512         82        640: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/8  0.1s\r\u001B[K      18/20      3.72G      1.448      1.684      1.421        135        640: 12% â”â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/8 2.2it/s 0.3s<3.2s\r\u001B[K      18/20      3.72G      1.454      1.637      1.419        126        640: 25% â”â”â”â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2/8 3.5it/s 0.4s<1.7s\r\u001B[K      18/20      3.72G      1.486      1.651      1.433        146        640: 38% â”â”â”â”â”€â”€â”€â”€â”€â”€â”€â”€ 3/8 4.2it/s 0.6s<1.2s\r\u001B[K      18/20      3.72G      1.453      1.658      1.431         90        640: 50% â”â”â”â”â”â”â”€â”€â”€â”€â”€â”€ 4/8 5.4it/s 0.7s<0.7s\r\u001B[K      18/20      3.72G      1.432      1.605      1.405         87        640: 62% â”â”â”â”â”â”â”â”€â”€â”€â”€â”€ 5/8 6.1it/s 0.8s<0.5s\r\u001B[K      18/20      3.72G      1.436      1.602      1.435         79        640: 75% â”â”â”â”â”â”â”â”â”â”€â”€â”€ 6/8 6.6it/s 1.0s<0.3s\r\u001B[K      18/20      3.72G      1.449      1.633       1.43        133        640: 88% â”â”â”â”â”â”â”â”â”â”â”€â”€ 7/8 6.3it/s 1.1s<0.2s\r\u001B[K      18/20      3.72G      1.449      1.633       1.43        133        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 7.0it/s 1.1s\r\u001B[K      18/20      3.72G      1.449      1.633       1.43        133        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 7.0it/s 1.1s\n\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 25% â”â”â”â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/4 1.6it/s 0.2s<1.8s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 50% â”â”â”â”â”â”â”€â”€â”€â”€â”€â”€ 2/4 2.8it/s 0.4s<0.7s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 75% â”â”â”â”â”â”â”â”â”â”€â”€â”€ 3/4 3.4it/s 0.6s<0.3s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 5.3it/s 0.8s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 5.3it/s 0.8s\n                   all        128        929      0.814      0.546       0.67      0.438\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\r\u001B[K      19/20      3.72G      1.414      1.819       1.44        124        640: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/8  0.1s\r\u001B[K      19/20      3.72G      1.425       1.77      1.503         68        640: 12% â”â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/8 2.4it/s 0.3s<3.0s\r\u001B[K      19/20      3.72G      1.412      1.769      1.476         93        640: 25% â”â”â”â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2/8 3.9it/s 0.4s<1.5s\r\u001B[K      19/20      3.72G      1.438      1.751      1.447        147        640: 38% â”â”â”â”â”€â”€â”€â”€â”€â”€â”€â”€ 3/8 4.4it/s 0.6s<1.1s\r\u001B[K      19/20      3.72G      1.437      1.707      1.429        158        640: 50% â”â”â”â”â”â”â”€â”€â”€â”€â”€â”€ 4/8 5.4it/s 0.7s<0.7s\r\u001B[K      19/20      3.72G      1.411      1.637      1.394        101        640: 62% â”â”â”â”â”â”â”â”€â”€â”€â”€â”€ 5/8 6.7it/s 0.8s<0.4s\r\u001B[K      19/20      3.72G      1.393      1.616      1.394         74        640: 88% â”â”â”â”â”â”â”â”â”â”â”€â”€ 7/8 7.5it/s 1.0s<0.1s\r\u001B[K      19/20      3.72G      1.393      1.616      1.394         74        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 7.8it/s 1.0s\r\u001B[K      19/20      3.72G      1.393      1.616      1.394         74        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 7.8it/s 1.0s\n\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 25% â”â”â”â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/4 2.5it/s 0.1s<1.2s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 50% â”â”â”â”â”â”â”€â”€â”€â”€â”€â”€ 2/4 4.1it/s 0.2s<0.5s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 75% â”â”â”â”â”â”â”â”â”â”€â”€â”€ 3/4 5.0it/s 0.4s<0.2s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 7.8it/s 0.5s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 7.8it/s 0.5s\n                   all        128        929      0.812      0.544      0.669      0.441\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\r\u001B[K      20/20      3.73G      1.288      1.665      1.329        129        640: 12% â”â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/8 1.6it/s 0.2s<4.3s\r\u001B[K      20/20      3.73G      1.438       1.61       1.36        131        640: 38% â”â”â”â”â”€â”€â”€â”€â”€â”€â”€â”€ 3/8 3.9it/s 0.4s<1.3s\r\u001B[K      20/20      3.73G      1.391      1.587      1.359        129        640: 62% â”â”â”â”â”â”â”â”€â”€â”€â”€â”€ 5/8 5.9it/s 0.6s<0.5s\r\u001B[K      20/20      3.73G      1.419      1.637      1.368         97        640: 88% â”â”â”â”â”â”â”â”â”â”â”€â”€ 7/8 6.8it/s 0.8s<0.1s\r\u001B[K      20/20      3.73G      1.419      1.637      1.368         97        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 9.8it/s 0.8s\r\u001B[K      20/20      3.73G      1.419      1.637      1.368         97        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 9.8it/s 0.8s\n\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 25% â”â”â”â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/4 2.6it/s 0.1s<1.2s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 50% â”â”â”â”â”â”â”€â”€â”€â”€â”€â”€ 2/4 4.4it/s 0.2s<0.5s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 75% â”â”â”â”â”â”â”â”â”â”€â”€â”€ 3/4 5.0it/s 0.4s<0.2s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 6.9it/s 0.6s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 6.9it/s 0.6s\n                   all        128        929      0.643      0.622      0.669      0.442\n\n20 epochs completed in 0.020 hours.\nOptimizer stripped from /tmp/training_results/train/weights/last.pt, 5.5MB\nOptimizer stripped from /tmp/training_results/train/weights/best.pt, 5.5MB\n\nValidating /tmp/training_results/train/weights/best.pt...\nUltralytics 8.3.204 ğŸš€ Python-3.12.3 torch-2.7.1+cu126 CUDA:0 (NVIDIA A10G, 22503MiB)\nYOLO11n summary (fused): 100 layers, 2,616,248 parameters, 0 gradients, 6.5 GFLOPs\n\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 25% â”â”â”â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/4 1.5it/s 0.2s<1.9s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 50% â”â”â”â”â”â”â”€â”€â”€â”€â”€â”€ 2/4 2.5it/s 0.4s<0.8s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 75% â”â”â”â”â”â”â”â”â”â”€â”€â”€ 3/4 1.8it/s 4.3s<0.6s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.9it/s 4.4s\r\u001B[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.9it/s 4.4s\n                   all        128        929      0.678      0.591      0.678      0.511\n                person         61        254      0.779      0.681       0.78      0.539\n               bicycle          3          6      0.411      0.167       0.42      0.242\n                   car         12         46      0.638      0.196      0.259      0.176\n            motorcycle          4          5      0.707          1      0.995      0.789\n              airplane          5          6      0.838      0.833      0.972      0.854\n                   bus          5          7      0.762      0.714      0.702      0.633\n                 train          3          3      0.707          1       0.83      0.714\n                 truck          5         12       0.55       0.25      0.362      0.227\n                  boat          2          6      0.708        0.5      0.543      0.332\n         traffic light          4         14      0.535      0.168      0.239      0.164\n             stop sign          2          2      0.833          1      0.995      0.797\n                 bench          5          9      0.895      0.444      0.654      0.341\n                  bird          2         16      0.954          1      0.995      0.651\n                   cat          4          4      0.871          1      0.995      0.834\n                   dog          9          9      0.697      0.778      0.919       0.74\n                 horse          1          2      0.539          1      0.995      0.796\n              elephant          4         17      0.888      0.931      0.941      0.754\n                  bear          1          1      0.618          1      0.995      0.995\n                 zebra          2          4       0.85          1      0.995      0.971\n               giraffe          4          9      0.837      0.889      0.968      0.727\n              backpack          4          6      0.657      0.333      0.401      0.204\n              umbrella          4         18      0.902      0.512      0.741       0.42\n               handbag          9         19      0.383     0.0526      0.168       0.11\n                   tie          6          7      0.947      0.571      0.787      0.578\n              suitcase          2          4      0.752          1      0.995      0.626\n               frisbee          5          5      0.688        0.8      0.759      0.703\n                  skis          1          1       0.64          1      0.995      0.597\n             snowboard          2          7      0.806      0.598      0.799      0.424\n           sports ball          6          6      0.577      0.461      0.521      0.328\n                  kite          2         10      0.645        0.4      0.551      0.207\n          baseball bat          4          4      0.496       0.25       0.43      0.171\n        baseball glove          4          7      0.715      0.286      0.359      0.176\n            skateboard          3          5          1      0.588      0.616      0.426\n         tennis racket          5          7      0.621      0.429      0.616      0.322\n                bottle          6         18      0.592      0.323      0.482      0.297\n            wine glass          5         16      0.784      0.455      0.697      0.375\n                   cup         10         36      0.726      0.295      0.408      0.286\n                  fork          6          6      0.581      0.167      0.248      0.205\n                 knife          7         16      0.705      0.449      0.613      0.387\n                 spoon          5         22       0.91      0.273      0.433      0.277\n                  bowl          9         28      0.589      0.714      0.685      0.571\n                banana          1          1       0.48          1      0.995      0.895\n              sandwich          2          2      0.439        0.5      0.497      0.497\n                orange          1          4          1          0      0.845      0.602\n              broccoli          4         11      0.363      0.182      0.236      0.197\n                carrot          3         24      0.682        0.5      0.644      0.451\n               hot dog          1          2      0.547          1      0.995      0.995\n                 pizza          5          5      0.668          1      0.995      0.833\n                 donut          2         14      0.591          1      0.916      0.813\n                  cake          4          4      0.676          1      0.995      0.818\n                 chair          9         35      0.488      0.543      0.533      0.306\n                 couch          5          6      0.589      0.833      0.728      0.567\n          potted plant          9         14      0.739      0.571      0.731      0.512\n                   bed          3          3      0.604      0.542       0.83      0.607\n          dining table         10         13      0.525      0.538      0.546       0.45\n                toilet          2          2      0.614        0.5      0.562       0.55\n                    tv          2          2      0.605          1      0.995      0.846\n                laptop          2          3          1      0.523      0.863      0.777\n                 mouse          2          2          1          0          0          0\n                remote          5          8      0.691        0.5      0.518       0.46\n            cell phone          5          8          1          0      0.189      0.104\n             microwave          3          3      0.523          1      0.995      0.897\n                  oven          5          5      0.261        0.4      0.422      0.338\n                  sink          4          6      0.301      0.167      0.267      0.196\n          refrigerator          5          5      0.852          1      0.995      0.627\n                  book          6         29      0.434      0.106      0.362      0.196\n                 clock          8          9      0.879      0.889      0.875      0.733\n                  vase          2          2      0.455          1      0.995      0.945\n              scissors          1          1          0          0     0.0383    0.00383\n            teddy bear          6         21      0.812      0.429      0.706      0.495\n            toothbrush          2          5          1      0.745      0.995       0.62\nSpeed: 0.1ms preprocess, 18.8ms inference, 0.0ms loss, 12.5ms postprocess per image\nResults saved to \u001B[1m/tmp/training_results/train\u001B[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:databricks.sdk.mixins.files:Failed to abort upload: Can't infer requester network zone.\nWARNING:databricks.sdk.mixins.files:Failed to abort upload: Can't infer requester network zone.\n2025/10/07 19:23:31 DEBUG mlflow.store.artifact.databricks_tracking_artifact_repo: Failed to perform log_artifacts operation using Databricks SDK, falling back to DatabricksArtifactRepository. Original error: Can't infer requester network zone.\nTraceback (most recent call last):\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-787e12c8-81d4-49dc-a0a6-34a5a70ca19b/lib/python3.12/site-packages/mlflow/store/artifact/databricks_tracking_artifact_repo.py\", line 68, in log_artifacts\n    self.databricks_sdk_repo.log_artifacts(local_dir, artifact_path)\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-787e12c8-81d4-49dc-a0a6-34a5a70ca19b/lib/python3.12/site-packages/mlflow/store/artifact/databricks_sdk_artifact_repo.py\", line 110, in log_artifacts\n    fut.result()\n  File \"/usr/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/usr/lib/python3.12/concurrent/futures/thread.py\", line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-787e12c8-81d4-49dc-a0a6-34a5a70ca19b/lib/python3.12/site-packages/mlflow/store/artifact/databricks_sdk_artifact_repo.py\", line 82, in log_artifact\n    self.files_api.upload(\n  File \"/databricks/python/lib/python3.12/site-packages/databricks/sdk/mixins/files.py\", line 781, in upload\n    raise e from None\n  File \"/databricks/python/lib/python3.12/site-packages/databricks/sdk/mixins/files.py\", line 769, in upload\n    self._perform_multipart_upload(\n  File \"/databricks/python/lib/python3.12/site-packages/databricks/sdk/mixins/files.py\", line 846, in _perform_multipart_upload\n    upload_part_urls_response = self._api.do(\n                                ^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/databricks/sdk/core.py\", line 85, in do\n    return self._api_client.do(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/databricks/sdk/_base_client.py\", line 196, in do\n    response = call(\n               ^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/databricks/sdk/retries.py\", line 57, in wrapper\n    raise err\n  File \"/databricks/python/lib/python3.12/site-packages/databricks/sdk/retries.py\", line 36, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/databricks/python/lib/python3.12/site-packages/databricks/sdk/_base_client.py\", line 298, in _perform\n    raise error from None\ndatabricks.sdk.errors.platform.InternalError: Can't infer requester network zone.\n2025/10/07 19:26:55 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n2025/10/07 19:26:55 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mMLflow: \u001B[0mresults logged to databricks\n\u001B[34m\u001B[1mMLflow: \u001B[0mdisable with 'yolo settings mlflow=False'\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
       "\n",
       "ap_class_index: array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 11, 13, 14, 15, 16, 17, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 79])\n",
       "box: ultralytics.utils.metrics.Metric object\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7f797c0a47a0>\n",
       "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
       "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1, ...,   0.0015334,  0.00076669,           0],\n",
       "       [          1,           1,           1, ...,  0.00020639,   0.0001032,           0],\n",
       "       [          1,           1,           1, ...,  9.8179e-05,   4.909e-05,           0],\n",
       "       ...,\n",
       "       [   0.038462,    0.038462,    0.038462, ...,    0.038462,    0.038462,           0],\n",
       "       [          1,           1,           1, ...,    0.003432,    0.001716,           0],\n",
       "       [          1,           1,           1, ...,           1,           1,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.11321,     0.11321,     0.14046, ...,           0,           0,           0],\n",
       "       [    0.03367,     0.03367,    0.042167, ...,           0,           0,           0],\n",
       "       [   0.046748,    0.046748,    0.065616, ...,           0,           0,           0],\n",
       "       ...,\n",
       "       [   0.036364,    0.036364,    0.056847, ...,           0,           0,           0],\n",
       "       [    0.15038,     0.15038,     0.17756, ...,           0,           0,           0],\n",
       "       [    0.10638,     0.10638,     0.16843, ...,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[   0.060309,    0.060309,    0.076048, ...,           1,           1,           1],\n",
       "       [   0.017182,    0.017182,    0.021772, ...,           1,           1,           1],\n",
       "       [    0.02452,     0.02452,    0.035112, ...,           1,           1,           1],\n",
       "       ...,\n",
       "       [   0.018519,    0.018519,    0.029255, ...,           1,           1,           1],\n",
       "       [   0.081633,    0.081633,    0.097908, ...,           1,           1,           1],\n",
       "       [    0.05618,     0.05618,    0.091961, ...,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.92126,     0.92126,     0.91769, ...,           0,           0,           0],\n",
       "       [    0.83333,     0.83333,     0.66667, ...,           0,           0,           0],\n",
       "       [        0.5,         0.5,         0.5, ...,           0,           0,           0],\n",
       "       ...,\n",
       "       [          1,           1,           1, ...,           0,           0,           0],\n",
       "       [    0.95238,     0.95238,     0.95238, ...,           0,           0,           0],\n",
       "       [          1,           1,           1, ...,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
       "fitness: np.float64(0.5112710378040302)\n",
       "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
       "maps: array([    0.53879,     0.24212,     0.17554,       0.789,     0.85408,     0.63295,     0.71418,     0.22707,      0.3319,     0.16426,     0.51127,     0.79739,     0.51127,     0.34147,     0.65074,     0.83447,     0.73974,     0.79627,     0.51127,     0.51127,     0.75445,       0.995,     0.97063,     0.72672,\n",
       "           0.20402,     0.41951,      0.1101,     0.57805,     0.62647,     0.70327,       0.597,     0.42361,     0.32777,     0.20698,     0.17115,      0.1761,     0.42625,     0.51127,     0.32241,     0.29684,     0.37479,     0.28643,     0.20515,      0.3867,       0.277,     0.57131,      0.8955,     0.51127,\n",
       "            0.4975,     0.60242,       0.197,     0.45097,       0.995,     0.83293,     0.81338,     0.81848,     0.30588,     0.56747,     0.51157,     0.60698,     0.44953,     0.54964,     0.84595,      0.7767,           0,      0.4604,     0.51127,     0.10408,     0.89686,     0.33825,     0.51127,     0.19571,\n",
       "           0.62703,     0.19599,     0.73328,     0.94512,   0.0038269,     0.49494,     0.51127,     0.62018])\n",
       "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
       "nt_per_class: array([254,   6,  46,   5,   6,   7,   3,  12,   6,  14,   0,   2,   0,   9,  16,   4,   9,   2,   0,   0,  17,   1,   4,   9,   6,  18,  19,   7,   4,   5,   1,   7,   6,  10,   4,   7,   5,   0,   7,  18,  16,  36,   6,  16,  22,  28,   1,   0,   2,   4,  11,  24,   2,   5,  14,   4,  35,   6,  14,   3,  13,   2,\n",
       "         2,   3,   2,   8,   0,   8,   3,   5,   0,   6,   5,  29,   9,   2,   1,  21,   0,   5])\n",
       "nt_per_image: array([61,  3, 12,  4,  5,  5,  3,  5,  2,  4,  0,  2,  0,  5,  2,  4,  9,  1,  0,  0,  4,  1,  2,  4,  4,  4,  9,  6,  2,  5,  1,  2,  6,  2,  4,  4,  3,  0,  5,  6,  5, 10,  6,  7,  5,  9,  1,  0,  2,  1,  4,  3,  1,  5,  2,  4,  9,  5,  9,  3, 10,  2,  2,  2,  2,  5,  0,  5,  3,  5,  0,  4,  5,  6,  8,  2,  1,  6,\n",
       "        0,  2])\n",
       "results_dict: {'metrics/precision(B)': 0.6782150568276637, 'metrics/recall(B)': 0.5912307841007075, 'metrics/mAP50(B)': 0.6777824255351341, 'metrics/mAP50-95(B)': 0.5112710378040302, 'fitness': 0.5112710378040302}\n",
       "save_dir: PosixPath('/tmp/training_results/train')\n",
       "speed: {'preprocess': 0.11751454686503848, 'inference': 18.79465327343155, 'loss': 0.0005024296854116983, 'postprocess': 12.472054976562674}\n",
       "stats: {'tp': [], 'conf': [], 'pred_cls': [], 'target_cls': [], 'target_img': []}\n",
       "task: 'detect'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = YOLO(f\"{project_location}/raw_model/yolo11n.pt\")\n",
    "model.train(\n",
    "    task=\"detect\",\n",
    "    batch=16, # Batch size, with three modes: set as an integer (e.g., batch=16), auto mode for 60% GPU memory utilization (batch=-1), or auto mode with specified utilization fraction (batch=0.70).\n",
    "    device=-1, # need to be LOCAL_RANK, i.e., 0 for this case since we already init_process_group beforehand. RANK wont work. There is no need to specify [0,1] given for example if we have 2 GPUs per node. [0,1] with world_size of 4 or 2 beforehand will both fail. \n",
    "    data=data_yaml_path,\n",
    "    epochs=20,\n",
    "    project=f'{tmp_project_location}', # local VM ephermal location\n",
    "    # project=f'{volume_project_location}', # volume path still wont work\n",
    "    exist_ok=True,\n",
    "    fliplr=1,\n",
    "    flipud=1,\n",
    "    perspective=0.001,\n",
    "    degrees=.45\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f27e1bbb-d077-4dc4-95e4-d8676d97eb97",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "working with 4 GPUs"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<!-- Tailwind CSS -->\n",
       "      <script src=\"https://cdn.tailwindcss.com\"></script>\n",
       "      <script>\n",
       "        tailwind.config = {\n",
       "          theme: {\n",
       "            extend: {\n",
       "              colors: {\n",
       "                primary: '#4F46E5',\n",
       "                secondary: '#6B7280'\n",
       "              },\n",
       "              borderRadius: {\n",
       "                'none': '0px',\n",
       "                'sm': '2px',\n",
       "                DEFAULT: '4px',\n",
       "                'md': '8px',\n",
       "                'lg': '12px',\n",
       "                'xl': '16px',\n",
       "                '2xl': '20px',\n",
       "                '3xl': '24px',\n",
       "                'full': '9999px',\n",
       "                'button': '4px'\n",
       "              }\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      </script>\n",
       "\n",
       "      <!-- Font Awesome -->\n",
       "      <link href=\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css\" rel=\"stylesheet\">\n",
       "\n",
       "      <!-- Google Fonts -->\n",
       "      <link rel=\"preconnect\" href=\"https://fonts.googleapis.com\">\n",
       "      <link rel=\"preconnect\" href=\"https://fonts.gstatic.com\" crossorigin>\n",
       "      <link href=\"https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap\" rel=\"stylesheet\">\n",
       "\n",
       "      <style>\n",
       "        body {\n",
       "          font-family: 'Inter', sans-serif;\n",
       "          background-color: #F9FAFB;\n",
       "          padding: 20px;\n",
       "        }\n",
       "        table {\n",
       "          border-collapse: separate;\n",
       "          border-spacing: 0;\n",
       "          width: 100%;\n",
       "          table-layout: fixed;\n",
       "        }\n",
       "        th {\n",
       "          position: sticky;\n",
       "          top: 0;\n",
       "          background-color: #F9FAFB;\n",
       "          z-index: 10;\n",
       "        }\n",
       "        th, td {\n",
       "          border-bottom: 1px solid #E5E7EB;\n",
       "          overflow: hidden;\n",
       "          text-overflow: ellipsis;\n",
       "          white-space: nowrap;\n",
       "        }\n",
       "        .status-badge {\n",
       "          display: inline-flex;\n",
       "          align-items: center;\n",
       "          padding: 2px 8px;\n",
       "          border-radius: 9999px;\n",
       "          font-size: 12px;\n",
       "          font-weight: 500;\n",
       "        }\n",
       "        .status-queued {\n",
       "          background-color: #FFF7ED;\n",
       "          color: #EA580C;\n",
       "        }\n",
       "        .status-running {\n",
       "          background-color: #EEF2FF;\n",
       "          color: #4F46E5;\n",
       "        }\n",
       "        .status-terminating {\n",
       "          background-color: #FFF3CD;\n",
       "          color: #FFB900;\n",
       "        }\n",
       "        .status-blocked {\n",
       "          background-color: #FDE8E8;\n",
       "          color: #B91C1C;\n",
       "        }\n",
       "        .status-pending {\n",
       "          background-color: #E0E7FF;\n",
       "          color: #4338CA;\n",
       "        }\n",
       "        .status-failed {\n",
       "          background-color: #FEF2F2;\n",
       "          color: #DC2626;\n",
       "        }\n",
       "        .status-success {\n",
       "          background-color: #ECFDF5;\n",
       "          color: #059669;\n",
       "        }\n",
       "      </style>\n",
       "\n",
       "      <div class=\"bg-white rounded-lg shadow overflow-x-auto\">\n",
       "        <table class=\"w-full\">\n",
       "          \n",
       "      <thead >\n",
       "        \n",
       "          <tr class=\"text-left text-xs text-gray-500 uppercase tracking-wider\">\n",
       "            <th class=\"px-6 py-3\">Name</th>\n",
       "            <th class=\"px-6 py-3\">GPUs</th>\n",
       "            <th class=\"px-6 py-3\">Instance</th>\n",
       "            <th class=\"px-6 py-3\">Params</th>\n",
       "            <th class=\"px-6 py-3\">Job Run</th>\n",
       "            <th class=\"px-6 py-3\">Status</th>\n",
       "            <th class=\"px-6 py-3\">Actions</th>\n",
       "          </tr>\n",
       "        \n",
       "      </thead>\n",
       "    \n",
       "          <tbody class=\"bg-white text-sm\">\n",
       "            <tr class=\"hover:bg-gray-50\">\n",
       "        <td class=\"px-6 py-4\">train_fn</td>\n",
       "        <td class=\"px-6 py-4\">4</td>\n",
       "        <td class=\"px-6 py-4\">OD A10</td>\n",
       "        <td class=\"px-6 py-4\">{'world_size': None, 'parent_run_id': None}</td>\n",
       "        <td class=\"px-6 py-4 text-primary\">\n",
       "            <a href=\"https://e2-dogfood.staging.cloud.databricks.com/?o=6051921418418893#job/250316223620713/run/758353951446338\" target=\"_blank\" rel=\"noopener noreferrer\" class=\"hover:underline\">874785386088047</a>\n",
       "        </td>\n",
       "        <td class=\"px-6 py-4\">\n",
       "            <span class=\"status-badge\" style=\"background-color: #ECFDF5; color: #059669;\">\n",
       "                COMPLETED\n",
       "                <i class='fas fa-check-circle ml-1 text-xs'></i>\n",
       "            </span>\n",
       "        </td>\n",
       "        <td class=\"px-6 py-4\">\n",
       "            \n",
       "            <a href=\"https://e2-dogfood.staging.cloud.databricks.com/ml/experiments/2518420765913308/runs/d36152b09e5f40bc8aaf472ec4a8a006/artifacts/logs/resumption_0/node_0/\" target=\"_blank\" rel=\"noopener noreferrer\" class=\"rounded-button text-primary hover:text-primary/80 whitespace-nowrap\">Full Logs</a>\n",
       "        <br>\n",
       "            <a href=\"https://e2-dogfood.staging.cloud.databricks.com/ml/experiments/2518420765913308/runs/d36152b09e5f40bc8aaf472ec4a8a006/system-metrics\" target=\"_blank\" rel=\"noopener noreferrer\" class=\"rounded-button text-primary hover:text-primary/80 whitespace-nowrap\">System Metrics</a>\n",
       "        \n",
       "        </td>\n",
       "    </tr>\n",
       "          </tbody>\n",
       "        </table>\n",
       "\n",
       "      </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['finished', 'finished', 'finished', 'finished']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings.update({\"mlflow\":True}) # if you do want to autolog.\n",
    "mlflow.autolog(disable = False)\n",
    "\n",
    "print('data_yaml_path is:', data_yaml_path)\n",
    "\n",
    "import logging\n",
    "logging.getLogger(\"mlflow\").setLevel(logging.DEBUG)\n",
    "\n",
    "\n",
    "@distributed(gpus=4, gpu_type='A10', remote=True)\n",
    "#: -----------worker func: this function is visible to each GPU device.-------------------\n",
    "def train_fn(world_size = None, parent_run_id = None):\n",
    "\n",
    "\n",
    "    # import os\n",
    "    # from ultralytics import YOLO\n",
    "    # import torch\n",
    "    # import mlflow\n",
    "    # import torch.distributed as dist\n",
    "    # from ultralytics import settings\n",
    "    # from mlflow.types.schema import Schema, ColSpec\n",
    "    # from mlflow.models.signature import ModelSignature\n",
    "    from ultralytics.utils import RANK, LOCAL_RANK\n",
    "\n",
    "    # Setup distributed training\n",
    "    rank, world_size, device = setup()\n",
    "\n",
    "    print(f\"Rank: {rank}, World Size: {world_size}, Device: {device}\")\n",
    "    print(f\"Rank: {RANK}, World Size: {world_size}, Device: {LOCAL_RANK}\")\n",
    "\n",
    "\n",
    "    print(f\"PyTorch version: {torch.__version__}\")\n",
    "    print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"CUDA device count: {torch.cuda.device_count()}\")\n",
    "        print(f\"Current CUDA device: {torch.cuda.current_device()}\")\n",
    "\n",
    "\n",
    "    ############################\n",
    "    os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"0\" # use 1 for synchronization operation, debugging model prefers this.\n",
    "    os.environ[\"NCCL_DEBUG\"] = \"INFO\" # \"WARN\" # for more debugging info on the NCCL side.\n",
    "    os.environ['MLFLOW_ENABLE_SYSTEM_METRICS_LOGGING'] = \"true\"\n",
    "    os.environ['MLFLOW_EXPERIMENT_NAME'] = experiment_name\n",
    "    # We set the experiment details here\n",
    "    experiment = mlflow.set_experiment(experiment_name)\n",
    "    \n",
    "    # # #: from repo issue https://github.com/ultralytics/ultralytics/issues/11680\n",
    "    # ## conclusion: doesn't work, has error :\"ValueError: Invalid CUDA 'device=0,1' requested. Use 'device=cpu' or pass valid CUDA device(s) if available, i.e. 'device=0' or 'device=0,1,2,3' for Multi-GPU.\"\n",
    "    # # torch.backends.cudnn.benchmark = False\n",
    "    # # torch.cuda.synchronize()\n",
    "    # print(f\"------Before init_process_group, we have: {RANK=} -- {LOCAL_RANK=}------\")\n",
    "    # dist.init_process_group(\n",
    "    #     backend=\"nccl\",\n",
    "    #     init_method=\"env://\",\n",
    "    #     world_size=world_size,\n",
    "    #     rank=RANK, # this must be from 0 to world_size - 1. LOCAL_RANK wont work.\n",
    "    # )\n",
    "    # print(f\"------After init_process_group, we have: {RANK=} -- {LOCAL_RANK=}------\")\n",
    "\n",
    "    print('data_yaml_path is:', data_yaml_path)\n",
    "    #\n",
    "    # with mlflow.start_run(run_id=parent_run_id):\n",
    "    with mlflow.start_run():\n",
    "        # model = YOLO(f\"yolov11n.pt\") # shared location\n",
    "        model = YOLO(f\"{project_location}/raw_model/yolo11n.pt\")\n",
    "        model.train(\n",
    "            task=\"detect\",\n",
    "            batch=16, # Batch size, with three modes: set as an integer (e.g., batch=16), auto mode for 60% GPU memory utilization (batch=-1), or auto mode with specified utilization fraction (batch=0.70).\n",
    "            device=[LOCAL_RANK], # need to be LOCAL_RANK, i.e., 0 for this case since we already init_process_group beforehand. RANK wont work. There is no need to specify [0,1] given for example if we have 2 GPUs per node. [0,1] with world_size of 4 or 2 beforehand will both fail. \n",
    "            data=data_yaml_path,\n",
    "            epochs=20,\n",
    "            project=f'{tmp_project_location}', # local VM ephermal location\n",
    "            # project=f'{volume_project_location}', # volume path still wont work\n",
    "            exist_ok=True,\n",
    "            fliplr=1,\n",
    "            flipud=1,\n",
    "            perspective=0.001,\n",
    "            degrees=.45\n",
    "        )\n",
    "        success = None\n",
    "        if RANK in (0, -1):\n",
    "            success = model.val()\n",
    "            if success:\n",
    "                model.export() # ref: https://docs.ultralytics.com/modes/export/#introduction\n",
    "        \n",
    "\n",
    "    active_run_id = mlflow.last_active_run().info.run_id\n",
    "    print(\"For YOLO autologging, active_run_id is: \", active_run_id)\n",
    "\n",
    "    # after training is done.\n",
    "    if not dist.is_initialized():\n",
    "      # import torch.distributed as dist\n",
    "      dist.init_process_group(\"nccl\")\n",
    "\n",
    "    local_rank = int(os.environ[\"LOCAL_RANK\"])\n",
    "    global_rank = int(os.environ[\"RANK\"])\n",
    "    world_size = int(os.environ[\"WORLD_SIZE\"])\n",
    "    print(f\"------After training, we have: RANK:{global_rank=} -- LOCAL_RANK:{local_rank=} -- world_size: {world_size=}------\")\n",
    "\n",
    "    if global_rank == 0:\n",
    "        with mlflow.start_run(run_id=active_run_id) as run:\n",
    "            mlflow.log_artifact(data_yaml_path, \"input_data_yaml\")\n",
    "            # mlflow.log_dict(data, \"data.yaml\")\n",
    "            mlflow.log_params({\"rank\":global_rank})\n",
    "            mlflow.pytorch.log_model(YOLO(str(model.trainer.best)), \"model\", signature=signature) # this succeeded\n",
    "\n",
    "    # clean up\n",
    "    cleanup()\n",
    "\n",
    "    return \"finished\" # can return any picklable object\n",
    "\n",
    "\n",
    "train_fn.distributed(world_size = None, parent_run_id = None) # now can program can run without specifying manually the parameters of world_size and parent_run_id. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6f734b7f-d542-4fff-9983-2fe8400cfcdf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Note: I want to test more than 8 GPUs, but currently the dogfood has 8 A10 limitations.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01870009-b544-4b31-a179-a2b66b9d3570",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "working with 8 GPUs"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<!-- Tailwind CSS -->\n",
       "      <script src=\"https://cdn.tailwindcss.com\"></script>\n",
       "      <script>\n",
       "        tailwind.config = {\n",
       "          theme: {\n",
       "            extend: {\n",
       "              colors: {\n",
       "                primary: '#4F46E5',\n",
       "                secondary: '#6B7280'\n",
       "              },\n",
       "              borderRadius: {\n",
       "                'none': '0px',\n",
       "                'sm': '2px',\n",
       "                DEFAULT: '4px',\n",
       "                'md': '8px',\n",
       "                'lg': '12px',\n",
       "                'xl': '16px',\n",
       "                '2xl': '20px',\n",
       "                '3xl': '24px',\n",
       "                'full': '9999px',\n",
       "                'button': '4px'\n",
       "              }\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      </script>\n",
       "\n",
       "      <!-- Font Awesome -->\n",
       "      <link href=\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css\" rel=\"stylesheet\">\n",
       "\n",
       "      <!-- Google Fonts -->\n",
       "      <link rel=\"preconnect\" href=\"https://fonts.googleapis.com\">\n",
       "      <link rel=\"preconnect\" href=\"https://fonts.gstatic.com\" crossorigin>\n",
       "      <link href=\"https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap\" rel=\"stylesheet\">\n",
       "\n",
       "      <style>\n",
       "        body {\n",
       "          font-family: 'Inter', sans-serif;\n",
       "          background-color: #F9FAFB;\n",
       "          padding: 20px;\n",
       "        }\n",
       "        table {\n",
       "          border-collapse: separate;\n",
       "          border-spacing: 0;\n",
       "          width: 100%;\n",
       "          table-layout: fixed;\n",
       "        }\n",
       "        th {\n",
       "          position: sticky;\n",
       "          top: 0;\n",
       "          background-color: #F9FAFB;\n",
       "          z-index: 10;\n",
       "        }\n",
       "        th, td {\n",
       "          border-bottom: 1px solid #E5E7EB;\n",
       "          overflow: hidden;\n",
       "          text-overflow: ellipsis;\n",
       "          white-space: nowrap;\n",
       "        }\n",
       "        .status-badge {\n",
       "          display: inline-flex;\n",
       "          align-items: center;\n",
       "          padding: 2px 8px;\n",
       "          border-radius: 9999px;\n",
       "          font-size: 12px;\n",
       "          font-weight: 500;\n",
       "        }\n",
       "        .status-queued {\n",
       "          background-color: #FFF7ED;\n",
       "          color: #EA580C;\n",
       "        }\n",
       "        .status-running {\n",
       "          background-color: #EEF2FF;\n",
       "          color: #4F46E5;\n",
       "        }\n",
       "        .status-terminating {\n",
       "          background-color: #FFF3CD;\n",
       "          color: #FFB900;\n",
       "        }\n",
       "        .status-blocked {\n",
       "          background-color: #FDE8E8;\n",
       "          color: #B91C1C;\n",
       "        }\n",
       "        .status-pending {\n",
       "          background-color: #E0E7FF;\n",
       "          color: #4338CA;\n",
       "        }\n",
       "        .status-failed {\n",
       "          background-color: #FEF2F2;\n",
       "          color: #DC2626;\n",
       "        }\n",
       "        .status-success {\n",
       "          background-color: #ECFDF5;\n",
       "          color: #059669;\n",
       "        }\n",
       "      </style>\n",
       "\n",
       "      <div class=\"bg-white rounded-lg shadow overflow-x-auto\">\n",
       "        <table class=\"w-full\">\n",
       "          \n",
       "      <thead >\n",
       "        \n",
       "          <tr class=\"text-left text-xs text-gray-500 uppercase tracking-wider\">\n",
       "            <th class=\"px-6 py-3\">Name</th>\n",
       "            <th class=\"px-6 py-3\">GPUs</th>\n",
       "            <th class=\"px-6 py-3\">Instance</th>\n",
       "            <th class=\"px-6 py-3\">Params</th>\n",
       "            <th class=\"px-6 py-3\">Job Run</th>\n",
       "            <th class=\"px-6 py-3\">Status</th>\n",
       "            <th class=\"px-6 py-3\">Actions</th>\n",
       "          </tr>\n",
       "        \n",
       "      </thead>\n",
       "    \n",
       "          <tbody class=\"bg-white text-sm\">\n",
       "            <tr class=\"hover:bg-gray-50\">\n",
       "        <td class=\"px-6 py-4\">train_fn</td>\n",
       "        <td class=\"px-6 py-4\">8</td>\n",
       "        <td class=\"px-6 py-4\">OD A10</td>\n",
       "        <td class=\"px-6 py-4\">{'world_size': None, 'parent_run_id': None}</td>\n",
       "        <td class=\"px-6 py-4 text-primary\">\n",
       "            <a href=\"https://e2-dogfood.staging.cloud.databricks.com/?o=6051921418418893#job/376418308329152/run/950809838089863\" target=\"_blank\" rel=\"noopener noreferrer\" class=\"hover:underline\">351417196526889</a>\n",
       "        </td>\n",
       "        <td class=\"px-6 py-4\">\n",
       "            <span class=\"status-badge\" style=\"background-color: #ECFDF5; color: #059669;\">\n",
       "                COMPLETED\n",
       "                <i class='fas fa-check-circle ml-1 text-xs'></i>\n",
       "            </span>\n",
       "        </td>\n",
       "        <td class=\"px-6 py-4\">\n",
       "            \n",
       "            <a href=\"https://e2-dogfood.staging.cloud.databricks.com/ml/experiments/2518420765913308/runs/d1fc76e6a17c4576a35acc6148013674/artifacts/logs/resumption_0/node_0/\" target=\"_blank\" rel=\"noopener noreferrer\" class=\"rounded-button text-primary hover:text-primary/80 whitespace-nowrap\">Full Logs</a>\n",
       "        <br>\n",
       "            <a href=\"https://e2-dogfood.staging.cloud.databricks.com/ml/experiments/2518420765913308/runs/d1fc76e6a17c4576a35acc6148013674/system-metrics\" target=\"_blank\" rel=\"noopener noreferrer\" class=\"rounded-button text-primary hover:text-primary/80 whitespace-nowrap\">System Metrics</a>\n",
       "        \n",
       "        </td>\n",
       "    </tr>\n",
       "          </tbody>\n",
       "        </table>\n",
       "\n",
       "      </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['finished',\n",
       " 'finished',\n",
       " 'finished',\n",
       " 'finished',\n",
       " 'finished',\n",
       " 'finished',\n",
       " 'finished',\n",
       " 'finished']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings.update({\"mlflow\":True}) # if you do want to autolog.\n",
    "mlflow.autolog(disable = False)\n",
    "\n",
    "print('data_yaml_path is:', data_yaml_path)\n",
    "\n",
    "import logging\n",
    "logging.getLogger(\"mlflow\").setLevel(logging.DEBUG)\n",
    "\n",
    "\n",
    "@distributed(gpus=8, gpu_type='A10', remote=True)\n",
    "#: -----------worker func: this function is visible to each GPU device.-------------------\n",
    "def train_fn(world_size = None, parent_run_id = None):\n",
    "    try:\n",
    "        from ultralytics.utils import RANK, LOCAL_RANK\n",
    "\n",
    "        # Setup distributed training\n",
    "        rank, world_size, device = setup()\n",
    "\n",
    "        print(f\"Rank: {rank}, World Size: {world_size}, Device: {device}\")\n",
    "        print(f\"Rank: {RANK}, World Size: {world_size}, Device: {LOCAL_RANK}\")\n",
    "\n",
    "\n",
    "        print(f\"PyTorch version: {torch.__version__}\")\n",
    "        print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "        if torch.cuda.is_available():\n",
    "            print(f\"CUDA device count: {torch.cuda.device_count()}\")\n",
    "            print(f\"Current CUDA device: {torch.cuda.current_device()}\")\n",
    "\n",
    "\n",
    "        ############################\n",
    "        os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"0\" # use 1 for synchronization operation, debugging model prefers this.\n",
    "        os.environ[\"NCCL_DEBUG\"] = \"INFO\" # \"WARN\" # for more debugging info on the NCCL side.\n",
    "        os.environ['MLFLOW_ENABLE_SYSTEM_METRICS_LOGGING'] = \"true\"\n",
    "        os.environ['MLFLOW_EXPERIMENT_NAME'] = experiment_name\n",
    "        # We set the experiment details here\n",
    "        experiment = mlflow.set_experiment(experiment_name)\n",
    "        print('data_yaml_path is:', data_yaml_path)\n",
    "        \n",
    "        #\n",
    "        # with mlflow.start_run(run_id=parent_run_id):\n",
    "        with mlflow.start_run():\n",
    "            model = YOLO(f\"{project_location}/raw_model/yolo11n.pt\")\n",
    "            model.train(\n",
    "                task=\"detect\",\n",
    "                batch=16, # Batch size, with three modes: set as an integer (e.g., batch=16), auto mode for 60% GPU memory utilization (batch=-1), or auto mode with specified utilization fraction (batch=0.70).\n",
    "                device=[LOCAL_RANK], # need to be LOCAL_RANK, i.e., 0 for this case since we already init_process_group beforehand. RANK wont work. There is no need to specify [0,1] given for example if we have 2 GPUs per node. [0,1] with world_size of 4 or 2 beforehand will both fail. \n",
    "                data=data_yaml_path,\n",
    "                epochs=100,\n",
    "                project=f'{tmp_project_location}', # local VM ephermal location\n",
    "                # project=f'{volume_project_location}', # volume path still wont work\n",
    "                exist_ok=True,\n",
    "                fliplr=1,\n",
    "                flipud=1,\n",
    "                perspective=0.001,\n",
    "                degrees=.45\n",
    "            )\n",
    "            success = None\n",
    "            if RANK in (0, -1):\n",
    "                success = model.val()\n",
    "                if success:\n",
    "                    model.export() # ref: https://docs.ultralytics.com/modes/export/#introduction\n",
    "            \n",
    "\n",
    "        active_run_id = mlflow.last_active_run().info.run_id\n",
    "        print(\"For YOLO autologging, active_run_id is: \", active_run_id)\n",
    "\n",
    "        # after training is done.\n",
    "        if not dist.is_initialized():\n",
    "        # import torch.distributed as dist\n",
    "            dist.init_process_group(\"nccl\")\n",
    "\n",
    "        local_rank = int(os.environ[\"LOCAL_RANK\"])\n",
    "        global_rank = int(os.environ[\"RANK\"])\n",
    "        world_size = int(os.environ[\"WORLD_SIZE\"])\n",
    "        print(f\"------After training, we have: RANK:{global_rank=} -- LOCAL_RANK:{local_rank=} -- world_size: {world_size=}------\")\n",
    "\n",
    "        if global_rank == 0:\n",
    "            with mlflow.start_run(run_id=active_run_id) as run:\n",
    "                mlflow.log_artifact(data_yaml_path, \"input_data_yaml\")\n",
    "                # mlflow.log_dict(data, \"data.yaml\")\n",
    "                mlflow.log_params({\"rank\":global_rank})\n",
    "                mlflow.pytorch.log_model(YOLO(str(model.trainer.best)), \"model\", signature=signature) # this succeeded\n",
    "                #: TODO: we can log more stuff here\n",
    "        \n",
    "        return \"finished\" # can return any picklable object\n",
    "    \n",
    "    finally:\n",
    "        # clean up\n",
    "        cleanup()\n",
    "\n",
    "\n",
    "train_fn.distributed(world_size = None, parent_run_id = None) # now can program can run without specifying manually the parameters of world_size and parent_run_id. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "87d309f1-0740-443d-8e4b-ac3f9aa2336a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook provides a comprehensive, practical guide for distributed YOLO training on Databricks Serverless GPU Compute (SGC) with AWS, leveraging Unity Catalog for data management and MLflow for experiment tracking. The workflow covers:\n",
    "\n",
    "- **Environment Setup**: Automated installation of required packages and configuration of GPU resources.\n",
    "- **Data Preparation**: Structured dataset management using Unity Catalog Volumes, with clear instructions for updating dataset paths and handling data I/O.\n",
    "- **Distributed Training**: Implementation of PyTorch DDP for scalable multi-GPU training, including robust resource management and fault tolerance.\n",
    "- **MLflow Integration**: Seamless experiment tracking, model logging, and artifact management for reproducibility and analysis.\n",
    "- **Performance Optimization**: Guidance on NCCL network tuning, batch size selection, worker configuration, and system metrics monitoring to maximize training efficiency.\n",
    "- **Troubleshooting**: Documentation of common issues (e.g., NCCL warnings, CUDA memory errors) and actionable solutions for debugging distributed training jobs.\n",
    "\n",
    "**Key Takeaways:**\n",
    "- The notebook demonstrates how to scale YOLO object detection training efficiently on Databricks, with both 4-GPU and 8-GPU examples.\n",
    "- MLflow integration ensures robust experiment tracking and model versioning, supporting production-grade workflows.\n",
    "- Recommendations for cluster/network configuration and training parameters help optimize performance and resource utilization.\n",
    "- The workflow is extensible to larger GPU clusters and can be adapted for other deep learning models and datasets.\n",
    "\n",
    "By following these steps and best practices, you can accelerate computer vision research and production workloads on Databricks, taking full advantage of serverless and dedicated GPU infrastructure.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8ddad580-69de-42ca-a139-7ec1aea8b568",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Supplemental Below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9621cf66-f949-4cb7-ad66-4305d4a68746",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 1. Tip about if too long waiting and job failed in node launching stage.\n",
    "For GPU resource not ready timeout error, consider to add these settings.\n",
    "\n",
    "error msg: \"torch.distributed.DistStoreError: Timed out after 601 seconds waiting for clients. 7/8 clients joined.\"\n",
    "\n",
    "```\n",
    "os.environ['TORCH_DISTRIBUTED_TIMEOUT'] = '7200'\n",
    "\n",
    "import os\n",
    "os.environ['NCCL_ASYNC_ERROR_HANDLING'] = '1'  # Recommended for better error reporting\n",
    "os.environ['NCCL_BLOCKING_WAIT'] = '1'         # Wait for full timeout\n",
    "os.environ['NCCL_SOCKET_TIMEOUT'] = '600'      # Set a socket timeout in seconds\n",
    "os.environ['NCCL_DEBUG'] = 'INFO'              # Enable debug logs\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "67fc89a3-ec60-45d1-a3ae-421f6d931c50",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2. Overall Log Screening and Recommendations\n",
    "\n",
    "# Analysis of YOLO Training Log and Optimization Recommendations\n",
    "\n",
    "Based on the comprehensive analysis of your training log and research into distributed training best practices, here are the key areas for improvement in your cluster and training job configuration.\n",
    "\n",
    "## **Major Issues Identified**\n",
    "\n",
    "### **1. NCCL Network Communication Problems**\n",
    "\n",
    "The most significant issue in your log is the **failed NCCL network initialization**[1][2][3]. The errors show:\n",
    "\n",
    "- `NET/OFI aws-ofi-nccl initialization failed`\n",
    "- `NET/OFI Unable to find a protocol that worked`\n",
    "- `Using network Socket` (fallback to slower TCP networking)\n",
    "\n",
    "This means your distributed training is **falling back to slower Socket-based communication** instead of using optimized network fabrics, significantly reducing performance[4][5].\n",
    "\n",
    "### **2. Suboptimal Batch Size and Worker Configuration**\n",
    "\n",
    "Your current setup shows **8 dataloader workers** with an unspecified batch size. Research indicates this configuration may not be optimal for your 8-GPU setup[6][7][8].\n",
    "\n",
    "### **3. Databricks Serverless GPU Beta Limitations**\n",
    "\n",
    "The warning `serverless_gpu is in Beta. The API is subject to change` indicates you're using experimental infrastructure that may have performance and stability limitations[9][10].\n",
    "\n",
    "## **Cluster-Level Optimizations**\n",
    "\n",
    "### **Network Configuration**\n",
    "\n",
    "**Fix NCCL Network Issues:**\n",
    "- Set `NCCL_SOCKET_IFNAME=eth0` explicitly in your environment variables[3][11]\n",
    "- Add `NCCL_DEBUG=INFO` to get detailed networking information[12][11]\n",
    "- For AWS environments, ensure EFA (Elastic Fabric Adapter) is properly configured if available[4][13]\n",
    "\n",
    "**Recommended Environment Variables:**\n",
    "```bash\n",
    "export NCCL_SOCKET_IFNAME=eth0\n",
    "export NCCL_DEBUG=INFO\n",
    "export NCCL_NET=\"Socket\"  # Explicit fallback if EFA unavailable\n",
    "```\n",
    "\n",
    "### **Multi-GPU Setup Optimization**\n",
    "\n",
    "**Move from Serverless to Dedicated GPU Cluster:**\n",
    "Consider migrating from Databricks Serverless GPU (Beta) to a dedicated multi-GPU cluster for production training[14][15]. **Single-node multi-GPU setups typically outperform multi-node configurations** for YOLO training due to reduced network overhead[14].\n",
    "\n",
    "**Optimal Hardware Configuration:**\n",
    "- **Single node with 8 GPUs** is likely faster than 8 nodes with 1 GPU each[14]\n",
    "- Use **cluster placement groups** to minimize network latency[4]\n",
    "- Ensure all nodes have **identical PyTorch, CUDA, and NCCL versions**[16]\n",
    "\n",
    "## **Training Job Optimizations**\n",
    "\n",
    "### **Batch Size Optimization** \n",
    "\n",
    "**Use Automatic Batch Size Detection:**\n",
    "```python\n",
    "# Use batch=-1 for automatic optimal batch size calculation\n",
    "model.train(data=\"coco128.yaml\", epochs=100, batch=-1, device=[0,1,2,3,4,5,6,7])\n",
    "```\n",
    "\n",
    "This will automatically determine the **maximum batch size your GPUs can handle**[6][7], which is typically more efficient than manual guessing.\n",
    "\n",
    "**Manual Batch Size Guidelines:**\n",
    "- For 8 GPUs: Start with **batch=64** (8 per GPU) and scale up[6]\n",
    "- **Batch sizes of 16, 32, or 64 typically yield best results**[6]\n",
    "- Monitor GPU memory usage and increase until you approach memory limits[7]\n",
    "\n",
    "### **Dataloader Worker Optimization**\n",
    "\n",
    "**Reduce Worker Count:**\n",
    "Your current **8 workers may be excessive** for this setup[6][17]. Try:\n",
    "```python\n",
    "# Start with fewer workers to reduce RAM usage\n",
    "model.train(workers=4)  # or workers=2\n",
    "```\n",
    "\n",
    "**Memory Management:**\n",
    "- Disable image caching if experiencing high RAM usage: `cache=False`[17][18]\n",
    "- Monitor RAM usage during training - high worker counts can exhaust system memory[17]\n",
    "\n",
    "### **Training Parameters**\n",
    "\n",
    "**Enable Mixed Precision Training:**\n",
    "```python\n",
    "model.train(amp=True)  # Automatic Mixed Precision\n",
    "```\n",
    "This can **improve training speed and reduce memory usage** without sacrificing accuracy[7].\n",
    "\n",
    "**Optimize Image Processing:**\n",
    "```python\n",
    "model.train(\n",
    "    data=\"coco128.yaml\",\n",
    "    epochs=100, \n",
    "    batch=-1,           # Auto-detect optimal batch size\n",
    "    workers=4,          # Reduced worker count\n",
    "    device=[0,1,2,3,4,5,6,7],  # All 8 GPUs\n",
    "    amp=True,           # Mixed precision\n",
    "    cache=False         # Disable caching if RAM limited\n",
    ")\n",
    "```\n",
    "\n",
    "## **Monitoring and Debugging**\n",
    "\n",
    "### **Performance Monitoring**\n",
    "\n",
    "**Add NCCL Debugging:**\n",
    "Set `NCCL_DEBUG=INFO` to monitor network communication efficiency[3][11]. Look for:\n",
    "- Successful network initialization messages\n",
    "- Bandwidth utilization statistics\n",
    "- Communication pattern optimization\n",
    "\n",
    "**Track Key Metrics:**\n",
    "- **GPU utilization** (should be >90% during training)\n",
    "- **Network bandwidth utilization**\n",
    "- **Memory usage** (both GPU and system RAM)\n",
    "- **Training iteration time** and consistency[14]\n",
    "\n",
    "### **Troubleshooting Steps**\n",
    "\n",
    "1. **Test NCCL Communication:**\n",
    "   ```bash\n",
    "   # Run NCCL tests to verify network performance\n",
    "   python -c \"import torch; torch.distributed.init_process_group('nccl')\"\n",
    "   ```\n",
    "\n",
    "2. **Verify GPU Topology:**\n",
    "   Check GPU interconnects and ensure optimal placement[19]\n",
    "\n",
    "3. **Monitor Resource Usage:**\n",
    "   Use Databricks cluster metrics to identify bottlenecks[14]\n",
    "\n",
    "## **Long-term Recommendations**\n",
    "\n",
    "### **Infrastructure Migration**\n",
    "\n",
    "**Consider Moving to Production Infrastructure:**\n",
    "- Migrate from **Serverless GPU (Beta)** to stable, dedicated GPU clusters[9]\n",
    "- Use **instance types optimized for ML workloads** (e.g., p3, p4, g4 instances on AWS)[4]\n",
    "- Implement **proper EFA networking** for multi-node scenarios[20][4]\n",
    "\n",
    "### **Training Strategy**\n",
    "\n",
    "**Implement Progressive Training:**\n",
    "- Start with **smaller models and datasets** for parameter tuning\n",
    "- Use **gradient accumulation** if memory constraints limit batch size[7]\n",
    "- Consider **staged training** (train for shorter epochs, then resume) to avoid memory accumulation issues[17]\n",
    "\n",
    "The primary bottleneck in your current setup appears to be the **failed network optimization and suboptimal batch/worker configuration**. Addressing the NCCL networking issues should provide the most significant performance improvement, followed by optimizing batch size and reducing the worker count to prevent memory exhaustion.\n",
    "\n",
    "Sources\n",
    "[1] Slow NCCL gradient synchronization in distributed training https://discuss.pytorch.org/t/slow-nccl-gradient-synchronization-in-distributed-training/89625\n",
    "[2] Model Training with Ultralytics YOLO https://docs.ultralytics.com/modes/train/\n",
    "[3] NCCL Ignores Specified SOCKET_IFNAME Configuration ... - GitHub https://github.com/NVIDIA/nccl/issues/1581\n",
    "[4] Optimizing deep learning on P3 and P3dn with EFA - AWS https://aws.amazon.com/blogs/compute/optimizing-deep-learning-on-p3-and-p3dn-with-efa/\n",
    "[5] NCCL performance for Deep Learning workloads on AWS EFA ... https://github.com/NVIDIA/nccl/issues/235\n",
    "[6] What's an efficient way to fine tune the batch size? #3572 - GitHub https://github.com/ultralytics/ultralytics/issues/3572\n",
    "[7] Machine Learning Best Practices and Tips for Model Training https://docs.ultralytics.com/guides/model-training-tips/\n",
    "[8] I am seeing major improvements in my model and the only change ... https://community.ultralytics.com/t/i-am-seeing-major-improvements-in-my-model-and-the-only-change-has-been-the-machine-it-is-trained-on/1019\n",
    "[9] Serverless GPU compute | Databricks on AWS https://docs.databricks.com/aws/en/compute/serverless/gpu\n",
    "[10] Serverless GPU compute - Azure Databricks - Microsoft Learn https://learn.microsoft.com/en-us/azure/databricks/compute/serverless/gpu\n",
    "[11] How to set NCCL_SOCKET_IFNAME Â· Issue #286 Â· NVIDIA/nccl https://github.com/NVIDIA/nccl/issues/286\n",
    "[12] NCCL - CSCS Documentation https://docs.cscs.ch/software/communication/nccl/\n",
    "[13] Optimizing deep learning on P3 and P3dn with EFA - AWS https://aws.amazon.com/blogs/compute/optimizing-deep-learning-on-p3-and-p3dn-with-efa-part-1/\n",
    "[14] Best practices for deep learning on Databricks https://docs.databricks.com/aws/en/machine-learning/train-model/dl-best-practices\n",
    "[15] Multi-GPU and multi-node distributed training | Databricks on AWS https://docs.databricks.com/aws/en/machine-learning/sgc-examples/gpu-distributed-training\n",
    "[16] Multi node training of YOLOv8 (2 machine with 4GPU each) #7038 https://github.com/ultralytics/ultralytics/issues/7038\n",
    "[17] High RAM utilization during training - PyTorch Forums https://discuss.pytorch.org/t/high-ram-utilization-during-training/159939\n",
    "[18] how to avoid high RAM usage Â· Issue #1467 - GitHub https://github.com/ultralytics/ultralytics/issues/1467\n",
    "[19] Distributed Parallel Training: PyTorch Multi-GPU Setup in Kaggle T4x2 https://learnopencv.com/distributed-parallel-training-pytorch-multi-gpu-setup/\n",
    "[20] Get started with EFA and NCCL for ML workloads on Amazon EC2 https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/efa-start-nccl.html\n",
    "[21] DDP: multi node training Â· Issue #6286 - GitHub https://github.com/ultralytics/ultralytics/issues/6286\n",
    "[22] Multi-GPU Training with YOLOv5 - Ultralytics YOLO Docs https://docs.ultralytics.com/yolov5/tutorials/multi_gpu_training/\n",
    "[23] Neuron Runtime Troubleshooting on Inf1, Inf2 and Trn1 https://awsdocs-neuron.readthedocs-hosted.com/en/latest/neuron-runtime/nrt-troubleshoot.html\n",
    "[24] Enabling Fast Inference and Resilient Training with NCCL 2.27 https://developer.nvidia.com/blog/enabling-fast-inference-and-resilient-training-with-nccl-2-27/\n",
    "[25] How to train yolov8 with multi-gpu? Â· Issue #3308 - GitHub https://github.com/ultralytics/ultralytics/issues/3308\n",
    "[26] [bug] NCCL WARN NET/OFI Only EFA provider is supported #2675 https://github.com/aws/deep-learning-containers/issues/2675\n",
    "[27] Issues when trying to train on a multi-GPU device #5244 - GitHub https://github.com/ultralytics/ultralytics/issues/5244\n",
    "[28] Version Â· Issue #391 Â· aws/aws-ofi-nccl - GitHub https://github.com/aws/aws-ofi-nccl/issues/391\n",
    "[29] Distributed Training: Definition & How it Works - Ultralytics https://www.ultralytics.com/glossary/distributed-training\n",
    "[30] Using EFA on the DLAMI - AWS Deep Learning AMIs https://docs.aws.amazon.com/dlami/latest/devguide/tutorial-efa-using.html\n",
    "[31] On the Performance and Memory Footprint of Distributed Training https://arxiv.org/html/2407.02081v1\n",
    "[32] YOLO v11 training multi-GPU DDP Errors - Stack Overflow https://stackoverflow.com/questions/79372969/yolo-v11-training-multi-gpu-ddp-errors\n",
    "[33] Distributed Parallel Training Example (GPU) https://www.mindspore.cn/tutorials/experts/en/r2.0.0-alpha/parallel/train_gpu.html\n",
    "[34] Configure YOLOv8 for GPU: Accelerate Object Detection https://www.digitalocean.com/community/tutorials/yolov8-for-gpu-accelerate-object-detection\n",
    "[35] Simplifying Training and GenAI Finetuning Using Serverless GPU ... https://www.youtube.com/watch?v=pQMeeQ_jGY0\n",
    "[36] aws-samples/eks-efa-examples - GitHub https://github.com/aws-samples/eks-efa-examples\n",
    "[37] Multi-GPU and multi-node distributed training - Azure Databricks https://learn.microsoft.com/en-us/azure/databricks/machine-learning/sgc-examples/gpu-distributed-training\n",
    "[38] Configuration - Ultralytics YOLO Docs https://docs.ultralytics.com/usage/cfg/\n",
    "[39] Best practices for performance efficiency | Databricks on AWS https://docs.databricks.com/aws/en/lakehouse-architecture/performance-efficiency/best-practices\n",
    "[40] YOLOv5 Study: mAP vs Batch-Size #2452 - GitHub https://github.com/ultralytics/yolov5/discussions/2452\n",
    "[41] High-Performance GPU Memory Transfer on AWS Sagemaker ... https://www.perplexity.ai/hub/blog/high-performance-gpu-memory-transfer-on-aws\n",
    "[42] ML Training Tip Of The Week #1: Optimizing GPU ... - 86677 https://community.databricks.com/t5/technical-blog/ml-training-tip-of-the-week-1-optimizing-gpu-utilization-in/ba-p/86677\n",
    "[43] Tips for Best YOLOv5 Training Results - Ultralytics YOLO Docs https://docs.ultralytics.com/yolov5/tutorials/tips_for_best_training_results/\n",
    "[44] NCCL error when using Sagemaker distributed training without ... https://stackoverflow.com/questions/75064559/nccl-error-when-using-sagemaker-distributed-training-without-specifying-a-distri\n",
    "[45] Normal then slow then crashing training - YOLO - Ultralytics https://community.ultralytics.com/t/normal-then-slow-then-crashing-training/1203\n",
    "[46] The usage of video memory fluctuates greatly during YOLO11 training https://github.com/ultralytics/ultralytics/issues/20860\n",
    "[47] Serverless compute plane networking - Azure Databricks https://learn.microsoft.com/en-us/azure/databricks/security/network/serverless-network-security/\n",
    "[48] Unable to see NCCL logs - PyTorch Forums https://discuss.pytorch.org/t/unable-to-see-nccl-logs/176114\n",
    "[49] Optimize GPU utilization while training - YOLO - Ultralytics https://community.ultralytics.com/t/optimize-gpu-utilization-while-training/768\n",
    "[50] https://raw.githubusercontent.com/aws-samples/awso... https://raw.githubusercontent.com/aws-samples/awsome-distributed-training/main/1.architectures/efa-cheatsheet.md\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "78dfd331-f622-494b-b38a-8990ad553475",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**NCCL logs issues + recommendations** map.  \n",
    "\n",
    "---\n",
    "\n",
    "## ğŸš© Issues Observed in Your Logs\n",
    "\n",
    "1. **Transport Layer**\n",
    "   - NCCL is falling back to **`NET/Socket`** transport.  \n",
    "   - This is functional but **subâ€‘optimal** for multiâ€‘node training if you have InfiniBand, RoCE, or AWS EFA available.  \n",
    "   - GPUDirect RDMA (`GDR`) is disabled (`GDR 0`), so GPU memory copies are going through host memory.\n",
    "\n",
    "2. **CollNet / NVLink**\n",
    "   - Logs show `2 collnet channels` but also earlier warnings about missing `ncclCollNetPlugin_v10`.  \n",
    "   - CollNet is provisioned but not actually active.  \n",
    "   - `MNNVL 0` and `0 nvls channels` confirm no NVLink multiâ€‘node or NVLinkâ€‘SHARP acceleration.\n",
    "\n",
    "3. **Tuner Plugin**\n",
    "   - NCCL tried to load `libnccl-tuner.so` and failed, falling back to the **internal tuner**.  \n",
    "   - This is safe, but you lose the ability to autoâ€‘tune thresholds for your specific network.\n",
    "\n",
    "4. **P2P Support**\n",
    "   - `intraNodeP2pSupport 0 directMode 0` â†’ no GPUâ€‘toâ€‘GPU direct P2P.  \n",
    "   - Expected if you only have one GPU per node, but if you *do* have multiple GPUs per node, this means P2P isnâ€™t configured correctly.\n",
    "\n",
    "5. **Socket Parallelism**\n",
    "   - Using `2 threads` Ã— `8 sockets per thread`.  \n",
    "   - This is decent, but may not saturate highâ€‘bandwidth links if youâ€™re on a 100â€¯Gbps+ fabric.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ’¡ Recommendations\n",
    "\n",
    "### 1. Optimize Transport\n",
    "- If you have **InfiniBand or RoCE**:\n",
    "  ```bash\n",
    "  export NCCL_NET=IB\n",
    "  ```\n",
    "- If youâ€™re on **AWS with EFA**:\n",
    "  ```bash\n",
    "  export NCCL_NET=OFI\n",
    "  export FI_PROVIDER=efa\n",
    "  ```\n",
    "- If you only have Ethernet, sockets are fine, but you can tune them (see below).\n",
    "\n",
    "### 2. Enable GPUDirect RDMA (if hardware supports it)\n",
    "- Install Mellanox OFED drivers and ensure `nvidia-peermem` is loaded.  \n",
    "- Then NCCL should log `GDR 1` instead of `GDR 0`.\n",
    "\n",
    "### 3. CollNet / Hierarchical Collectives\n",
    "- If you want CollNet:\n",
    "  - Rebuild NCCL with `--with-collnet`.  \n",
    "  - Or install the NCCL package that includes CollNet support.  \n",
    "- If you donâ€™t need it, disable to avoid noise:\n",
    "  ```bash\n",
    "  export NCCL_COLLNET_ENABLE=0\n",
    "  ```\n",
    "\n",
    "### 4. Tuner Plugin\n",
    "- Optional: build or install `libnccl-tuner.so` if you want NCCL to autoâ€‘tune thresholds for your exact network.  \n",
    "- Otherwise, the internal tuner is fine.\n",
    "\n",
    "### 5. Socket Backend Tuning\n",
    "- Increase parallelism if youâ€™re bandwidthâ€‘limited:\n",
    "  ```bash\n",
    "  export NCCL_SOCKET_NTHREADS=4\n",
    "  export NCCL_NSOCKS_PERTHREAD=8\n",
    "  ```\n",
    "- Adjust based on CPU/network load.\n",
    "\n",
    "### 6. P2P (if multiâ€‘GPU per node)\n",
    "- Ensure GPUs are on the same PCIe root complex.  \n",
    "- Check with:\n",
    "  ```bash\n",
    "  nvidia-smi topo -m\n",
    "  ```\n",
    "- If P2P is supported, NCCL should show `intraNodeP2pSupport 1`.\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… Summary\n",
    "Right now, your setup is **working but not optimized**:  \n",
    "- Youâ€™re on **Socket transport** with no GPUDirect, no CollNet, and no tuner plugin.  \n",
    "- Thatâ€™s fine for functional correctness, but youâ€™re leaving performance on the table if you have faster interconnects.  \n",
    "\n",
    "---\n",
    "\n",
    "Would you like me to build you a **scenario matrix** (singleâ€‘node vs multiâ€‘node, Ethernet vs IB/EFA, with/without NVLink) that shows the *optimal NCCL env vars* for each case? That way youâ€™d have a readyâ€‘toâ€‘apply playbook depending on where you run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7acaa5bb-248c-4467-bae0-b86858c71f9b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.torch.distributor import TorchDistributor\n",
    "\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import mlflow\n",
    "import torch.distributed as dist\n",
    "from ultralytics import settings\n",
    "from mlflow.types.schema import Schema, ColSpec\n",
    "from mlflow.models.signature import ModelSignature\n",
    "from ultralytics.utils import RANK, LOCAL_RANK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9a7ddfb2-534a-4960-a1c3-9dd139bc8a65",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "I ran 4-6 tests with different CUDA device settings for the below minimal example to prove it wont work without the right setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3b3b98d-bfc0-45b0-b06d-86e4e7cbcdc9",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "(Prove minimal wont work)Minimal_example_v"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<!-- Tailwind CSS -->\n",
       "      <script src=\"https://cdn.tailwindcss.com\"></script>\n",
       "      <script>\n",
       "        tailwind.config = {\n",
       "          theme: {\n",
       "            extend: {\n",
       "              colors: {\n",
       "                primary: '#4F46E5',\n",
       "                secondary: '#6B7280'\n",
       "              },\n",
       "              borderRadius: {\n",
       "                'none': '0px',\n",
       "                'sm': '2px',\n",
       "                DEFAULT: '4px',\n",
       "                'md': '8px',\n",
       "                'lg': '12px',\n",
       "                'xl': '16px',\n",
       "                '2xl': '20px',\n",
       "                '3xl': '24px',\n",
       "                'full': '9999px',\n",
       "                'button': '4px'\n",
       "              }\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      </script>\n",
       "\n",
       "      <!-- Font Awesome -->\n",
       "      <link href=\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css\" rel=\"stylesheet\">\n",
       "\n",
       "      <!-- Google Fonts -->\n",
       "      <link rel=\"preconnect\" href=\"https://fonts.googleapis.com\">\n",
       "      <link rel=\"preconnect\" href=\"https://fonts.gstatic.com\" crossorigin>\n",
       "      <link href=\"https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap\" rel=\"stylesheet\">\n",
       "\n",
       "      <style>\n",
       "        body {\n",
       "          font-family: 'Inter', sans-serif;\n",
       "          background-color: #F9FAFB;\n",
       "          padding: 20px;\n",
       "        }\n",
       "        table {\n",
       "          border-collapse: separate;\n",
       "          border-spacing: 0;\n",
       "          width: 100%;\n",
       "          table-layout: fixed;\n",
       "        }\n",
       "        th {\n",
       "          position: sticky;\n",
       "          top: 0;\n",
       "          background-color: #F9FAFB;\n",
       "          z-index: 10;\n",
       "        }\n",
       "        th, td {\n",
       "          border-bottom: 1px solid #E5E7EB;\n",
       "          overflow: hidden;\n",
       "          text-overflow: ellipsis;\n",
       "          white-space: nowrap;\n",
       "        }\n",
       "        .status-badge {\n",
       "          display: inline-flex;\n",
       "          align-items: center;\n",
       "          padding: 2px 8px;\n",
       "          border-radius: 9999px;\n",
       "          font-size: 12px;\n",
       "          font-weight: 500;\n",
       "        }\n",
       "        .status-queued {\n",
       "          background-color: #FFF7ED;\n",
       "          color: #EA580C;\n",
       "        }\n",
       "        .status-running {\n",
       "          background-color: #EEF2FF;\n",
       "          color: #4F46E5;\n",
       "        }\n",
       "        .status-terminating {\n",
       "          background-color: #FFF3CD;\n",
       "          color: #FFB900;\n",
       "        }\n",
       "        .status-blocked {\n",
       "          background-color: #FDE8E8;\n",
       "          color: #B91C1C;\n",
       "        }\n",
       "        .status-pending {\n",
       "          background-color: #E0E7FF;\n",
       "          color: #4338CA;\n",
       "        }\n",
       "        .status-failed {\n",
       "          background-color: #FEF2F2;\n",
       "          color: #DC2626;\n",
       "        }\n",
       "        .status-success {\n",
       "          background-color: #ECFDF5;\n",
       "          color: #059669;\n",
       "        }\n",
       "      </style>\n",
       "\n",
       "      <div class=\"bg-white rounded-lg shadow overflow-x-auto\">\n",
       "        <table class=\"w-full\">\n",
       "          \n",
       "      <thead >\n",
       "        \n",
       "          <tr class=\"text-left text-xs text-gray-500 uppercase tracking-wider\">\n",
       "            <th class=\"px-6 py-3\">Name</th>\n",
       "            <th class=\"px-6 py-3\">GPUs</th>\n",
       "            <th class=\"px-6 py-3\">Instance</th>\n",
       "            <th class=\"px-6 py-3\">Params</th>\n",
       "            <th class=\"px-6 py-3\">Job Run</th>\n",
       "            <th class=\"px-6 py-3\">Status</th>\n",
       "            <th class=\"px-6 py-3\">Actions</th>\n",
       "          </tr>\n",
       "        \n",
       "      </thead>\n",
       "    \n",
       "          <tbody class=\"bg-white text-sm\">\n",
       "            <tr class=\"hover:bg-gray-50\">\n",
       "        <td class=\"px-6 py-4\">train_fn</td>\n",
       "        <td class=\"px-6 py-4\">8</td>\n",
       "        <td class=\"px-6 py-4\">OD A10</td>\n",
       "        <td class=\"px-6 py-4\">-</td>\n",
       "        <td class=\"px-6 py-4 text-primary\">\n",
       "            <a href=\"https://e2-dogfood.staging.cloud.databricks.com/?o=6051921418418893#job/1007822523268488/run/646739726656363\" target=\"_blank\" rel=\"noopener noreferrer\" class=\"hover:underline\">527009513539301</a>\n",
       "        </td>\n",
       "        <td class=\"px-6 py-4\">\n",
       "            <span class=\"status-badge\" style=\"background-color: #FEF2F2; color: #DC2626;\">\n",
       "                FAILED\n",
       "                <i class='fas fa-times-circle ml-1 text-xs'></i>\n",
       "            </span>\n",
       "        </td>\n",
       "        <td class=\"px-6 py-4\">\n",
       "            \n",
       "            <a href=\"https://e2-dogfood.staging.cloud.databricks.com/ml/experiments/2518420765913308/runs/df89005b258d40df9098edaeb4b40492/artifacts/logs/resumption_0/node_0/\" target=\"_blank\" rel=\"noopener noreferrer\" class=\"rounded-button text-primary hover:text-primary/80 whitespace-nowrap\">Full Logs</a>\n",
       "        <br>\n",
       "            <a href=\"https://e2-dogfood.staging.cloud.databricks.com/ml/experiments/2518420765913308/runs/df89005b258d40df9098edaeb4b40492/system-metrics\" target=\"_blank\" rel=\"noopener noreferrer\" class=\"rounded-button text-primary hover:text-primary/80 whitespace-nowrap\">System Metrics</a>\n",
       "        \n",
       "        </td>\n",
       "    </tr>\n",
       "          </tbody>\n",
       "        </table>\n",
       "\n",
       "      </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "ValueError('Default process group has not been initialized, please make sure to call init_process_group.')"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data_yaml_path = \"coco128.yaml\" # ref: https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/datasets/coco128.yaml\n",
    "\n",
    "@distributed(gpus=8, gpu_type='A10', remote=True)\n",
    "def train_fn():\n",
    "  # Start a run to represent the training job\n",
    "  with mlflow.start_run():\n",
    "    model = YOLO(f\"yolo11n\") # shared location\n",
    "    # model = YOLO(\"yolo11n\")\n",
    "    model.train(\n",
    "        task=\"detect\",\n",
    "        batch=16, # Batch size, with three modes: set as an integer (e.g., batch=16), auto mode for 60% GPU memory utilization (batch=-1), or auto mode with specified utilization fraction (batch=0.70).\n",
    "        device=[LOCAL_RANK], # need to be LOCAL_RANK, i.e., 0 for this case since we already init_process_group beforehand. RANK wont work. There is no need to specify [0,1] given for example if we have 2 GPUs per node. [0,1] with world_size of 4 or 2 beforehand will both fail. \n",
    "        data=data_yaml_path,\n",
    "        epochs=100,\n",
    "        project=f'{tmp_project_location}', # local VM ephermal location\n",
    "        # project=f'{volume_project_location}', # volume path still wont work\n",
    "        exist_ok=True,\n",
    "        fliplr=1,\n",
    "        flipud=1,\n",
    "        perspective=0.001,\n",
    "        degrees=.45\n",
    "    )\n",
    "\n",
    "train_fn.distributed()   \n",
    "\n",
    "## : conclusion\n",
    "## after a few iterations (with screenshots stored locally for error msgs from experiment log), we conclude it wont work for @distributed with simple setup.\n",
    "\n",
    "\n",
    "#: ----comment below out cause it was for classical GPU compute.----\n",
    "# distributor = TorchDistributor(num_processes=1, local_mode=True, use_gpu=True)      \n",
    "# distributor.run(train_fn)\n",
    "# # on sgc, error: [CONFIG_NOT_AVAILABLE] Configuration spark.master is not available. SQLSTATE: 42K0I"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": "A10",
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6482896598264492,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "03_quick test yolo11n with coco128 on SGC A10 Remote",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
